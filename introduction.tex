\chapter{Introduction}

\section*{Preface}

In this Chapter, the basic concepts and methodologies necessary to understand this Thesis as well as the state of the art within the field are introduced.

\section{The purpose of life}

``Long, long ago there was a time when nothing but mere matter existed in this world. In the teeming ooze, forms of a certain \textit{something} appeared, disappeared, and appeared again and one of them eventually survived. We know it as \textit{life}. The reason that \textit{life} ultimately survived was because it was in its nature \textit{to multiply}. \textit{Life} took new forms in order to multiply, adapting to every kind of environment, and culminating in \textit{us} today. Greater numbers, greater diversity, greater abundance. This is why we say that the purpose of \textit{life} is \textit{to multiply}.'' \cite{ISAYAMA_2021}

\section{Central dogma of molecular biology}

It is estimated based on geological \cite{SCHIDLOWSKI_1979_LIFE}, fossil \cite{SCHOPF_2007_LIFE} and phylogenetic \cite{BETTS_2018_LIFE} analyses that the origin of life in our planet Earth dates back to 3.7-4.0 billion years ago. Since then, \textit{life} has not just survived, but adapted and evolved to give raise to a gargantuan estimated biodiversity of 8.7 million eukaryotic species \cite{MORA_2011_SPECIES} and upward of 1 trillion microbial species \cite{HUG_2016_SPECIES, LOCEY_2016_SPECIES} with the vast majority of these still to be described \cite{COSTELLO_2013_SPECIES}. Despite the immense variation across species in terms of reproductive strategies, morphological, metabolic, behavioural traits or ecological niche, there is one thing \textit{all} species have in common: nucleic acids \cite{KOONIN_2011_LIFE}. All living species rely on nucleic acids, mostly deoxyribonucleic acid (DNA), except for some viruses \cite{KOONIN_2006_VIRUS} and viroids \cite{NAVARRO_2021_VIROIDS} that use ribonucleic acid (RNA), to store their genetic information. This information flows sequentially from DNA to RNA through the process of transcription and from RNA to protein through translation. This flow of molecular information is known as the \textit{Central Dogma of Molecular Biology} \cite{CRICK_1958_DOGMA, CRICK_1970_DOGMA}.

\section{The genetic code}

DNA is a polymer composed of two polynucleotide chains that coil around each other to form a double helix \cite{WATSON_1953_DNA}. These polymer chains are formed by simpler units called nucleotides. Each nucleotide presents a common scaffold formed of a deoxyribose sugar and a phosphate and a variable nitrogen-containing nucleobase. There are four different bases: adenine (A), thymine (T), cytosine (C) and guanine (G). The information stored in DNA gets transferred to RNA through the process of transcription. RNA tends to adopt a single-stranded conformation and is also formed by nucleotides. These nucleotides differ from DNA ones in that they present a ribose sugar, instead of deoxyribose, and an alternative uracil (U) nucleobase instead of thymine \cite{LEVENE_1909_NUCLEICS}.

Messenger RNA (mRNA) corresponds to the genetic sequence of a gene and is read by the ribosomal macromolecular machinery in the process of protein synthesis, or translation. In this process, a peptide chain is formed by linking amino acids in the order specified by the codons in the mRNA \cite{CRICK_1957_CODE}. A codon is a set of three nucleotides that corresponds to one of the twenty canonical amino acids. The equivalence between these codons and the amino acid they encode is known as the \textit{Genetic Code} \cite{GAMOW_1954_CODE}.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_INTRO/PNG/genetic_code.png}
    \caption[Genetic code]{\textbf{Genetic code.} Genetic code illustrating the 64 codons resulting from mRNA used to synthetise proteins in translation. Chemical structure of side chain is found next to each of the twenty amino acid names. Colour indicates basic amino acids (lavender), acidic (pink), polar (green) and nonpolar (yellow). STOP codons coloured in white. Image borrowed from Wikipedia: the free encyclopedia \cite{genetic_code_image}.}
    \label{fig:genetic_code}
\end{figure}

\section{Proteins}

Proteins are molecular machines that are involved in virtually all cellular processes including cell division, immune response or metabolism. They result from the process of translation of mRNA. Proteins are natural polymers formed of smaller monomers, called amino acids, linked to each other through peptide bonds.

\subsection{Amino acid structure}

There are twenty canonical amino acids that are found in all protein sequences. They receive this name because of their chemical structure, which includes both an amino and carboxylic acid functional groups. \autoref{fig:amino_acid} shows the general structure of an amino acid. A carbon atom is found in the centre which binds covalently to four different groups. This carbon is known as α-carbon (CA) and is attached to the amino group (--NH2), the carboxyl group (--COOH), a hydrogen atom (H) and a side chain (R) that differs across the twenty amino acid residues.

\begin{figure}[htbp!]
    \centering
    \includegraphics[width=0.50\textwidth]{figures/ch_INTRO/PNG/amino_acid.png}
    \caption[Amino acid structure]{\textbf{Amino acid structure.} All twenty amino acids share this common structure formed by the α-carbon (CA) chemically attached to the amino (NH2) and carboxyl (COOH) groups, a hydrogen atom (H), and a side chain (R). The side chain is different and defines the amino acids.}
    \label{fig:amino_acid}
\end{figure}

\subsection{Amino acid properties}

The different side chains of the amino acids confer them different physicochemical properties \cite{SNEATH_1966_PROPERTIES}. \autoref{fig:properties} illustrates the ten main properties, the relationship between them and which amino acids present them \cite{TAYLOR_1986_PROPERTIES}. The three most important properties setting amino acids apart are hydrophobicity, polarity and size. Hydrophobic residues present side chains that are less soluble in water and therefore tend to be located in the interior protein core, whereas hydrophilic residues are present on the surface. Polar residue side chains contain electronegative atoms like nitrogen (N) or oxygen (O) that favour interaction with water and other polar molecules. Size is also relevant as there is a big difference in volume between the amino acids ranging from 60 \AA{}\textsuperscript{3} (Glycine) to $>$200 \AA{}\textsuperscript{3} (Tryptophan). Within these three main categories, other subsets can be found as aliphatic (open chain of carbon atoms), aromatic (closed carbon chain), positively and negatively charged, tiny or proline. Proline has its own category because of its unique cyclical side chain which links back to the backbone \cite{ZVELEBIL_1987_PREDICTION}.

These physicochemical properties of amino acids are crucial to understand the arrangement of protein atoms in three-dimensional (3D) space and their conservation across evolutionarily related proteins is the basis for traditional sequence analysis and protein structure prediction \cite{CHOTHIA_1986_CONSERVATION}.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.90\textwidth]{figures/ch_INTRO/PNG/properties.png}
    \caption[Amino acid properties]{\textbf{Amino acid properties.} Taylor Venn diagram illustrating the different physicochemical properties of the twenty proteinogenic amino acids. Adapted from the Jalview website \cite{JALVIEW}, which in turn adapted from Livingstone and Barton \cite{LIVINGSTONE_1993_MSA}.}
    \label{fig:properties}
\end{figure}

\subsection{Substitution matrices}

Similar or identical protein sequences carrying out related functions and displaying a comparable 3D structure can be found within a genome (\textit{paralogous} sequences) and across species (\textit{ortholoous} sequences). These proteins are evolutionarily related, i.e., \textit{homologous}, and their origin can be traced back in time to a common ancestor. The comparative analysis of such related sequences provides insight into the evolutionary history of a given set of related sequences, or family \cite{BARTON_1990_MSA}. Amino acid substitution matrices can be calculated by quantifying the differences between closely related sequences. These matrices indicate the likelihood of observing transitions at a given protein position between the different amino acids. Transitions between amino acids with similar physicochemical properties, e.g., aspartate $\rightarrow$ glutamate, are less likely to alter the protein structure and are therefore observed with higher frequency. The Point Accepted Mutation (PAM) \cite{DAYHOFF_1978_PAM} and Block Substitution Matrix (BLOSUM) \cite{HENIKOFF_1992_BLOSUM} are some of the more relevant substitution matrices and serve as a scoring function for the construction of alignment of multiple sequences (MSA) that are related in evolution \cite{BARTON_1987_MSA}.

\subsection{Multiple sequence alignment}

In an multiple sequence alignment, more than two sequences (\textit{rows}) are piled up and aligned in a way that positions across proteins that are thought to be homologous, i.e., share common ancestry, are located on the same column \cite{NEEDLEMAN_1970_MSA}. Through time, sequences diverge and might suffer point mutations, insertions or deletions. To accommodate for this, aligners introduce \textit{gaps} (--) \cite{SMITH_1981_MSA}. By looking at the distribution of amino acid residues across columns in the alignment patterns of amino acid conservation can be observed when residues or their physicochemical properties are invariant across sequences or rows. Columns that present little or no variation are called \textit{conserved} whereas columns that present a wider variety of amino acids with different properties are called \textit{unconserved} or \textit{divergent} \cite{LIVINGSTONE_1993_CONS}. Many methods for the alignment of multiple sequences have been developed over the years with Clustal \cite{HIGGINS_1988_CLUSTAL, HIGGINS_1992_CLUSTALV, THOMPSON_1994_CLUSTALW, JEANMOUGIN_1998_CLUSTALX, SIEVERS_2011_CLUSTALO}, MAFFT \cite{KATOH_2002_MAFFT, KATOH_2008_MAFFT, KATOH_2013_MAFFT} or MUSCLE \cite{EDGAR_2004_MUSCLE, EDGAR_2022_MUSCLE5} being some of the most widely used. Jalview is a very powerful tool for the alignment, editing and integrative analysis of MSAs \cite{WATERHOUSE_2009_JALVIEW}.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.60\textwidth]{figures/ch_INTRO/PNG/anks_msa_short.png}
    \caption[Multiple sequence alignment]{\textbf{Multiple sequence alignment.} Fragment of an alignment of 7407 ankyrin repeat protein sequences built by Utgés \textit{et al.} \cite{UTGES_2021_ANKS}. The twenty sequences displayed on this figure all have the same length and so no gaps are observed. Alignment columns are coloured in the ClustalX colour scheme \cite{JEANMOUGIN_1998_CLUSTALX} with hydrophobic residues in blue, polar in green, glycine in orange, proline in yellow and aromatic in cyan. Additionally, columns are shaded by their conservation, so columns in darker colours are conserved through the alignment whilst those in lighter colours are divergent. The consensus sequence recapitulates the most common residues at each position. Secondary structure assignment describes de two α-helices located at columns 5-11 and 15-23 of the MSA. Strongly conserved residues include the TPLH motif at positions 4-7 as well as Ala9, Ala10, Leu21 and Leu22 which form a series of hydrophobic interactions stabilising he helices within individual repeats as well as across them. Sequence IDs are UniProt accessions numbers. Obtained with Jalview \cite{WATERHOUSE_2009_JALVIEW}.}
    \label{fig:MSA}
\end{figure}

\subsection{Amino acid conservation}

Amino acid conservation in MSAs is evidence of evolutionary constraint. Throughout evolution, conserved positions have remained fixed due to their functional or structural relevance, while divergent positions accumulate substitutions resulting in variability in amino acid residues across proteins within the same family \cite{ZUCKERKANDL_1965_DIVERGENCE}. There is not an obvious way to quantify amino acid conservation. Because of this, several scores exploring different approaches have been developed through the years \cite{VALDAR_2002_SCORES}. Some of these scores consider amino acids as symbols and use their relative frequencies \cite{WU_1970_SCORE, JORES_1990_SCORE, LOCKLESS_1999_SCORE}, or entropy \cite{SANDER_1991_SCORE, SHENKIN_1991_SCORE, GERSTEIN_1995_SCORE} to score conservation. Others focus on their stereochemical properties \cite{TAYLOR_1986_PROPERTIES, ZVELEBIL_1987_PREDICTION}, use mutation data \cite{KARLIN_1996_SCORE, THOMPSON_1997_SCORE, LANDGRAF_1999_SCORE, PILPEL_1999_SCORE, ARMON_2001_SCORE, VALDAR_2001_SCORE} or combine amino acid properties and symbol entropy \cite{WILLIAMSON_1995_SCORE, MIRNY_1999_SCORE}.

The score developed by Shenkin \textit{et al.} \cite{SHENKIN_1991_SCORE} is based on Shannon's Entropy ($S$) which is calculated with \autoref{eq:entropy_shannon2} \cite{SHANNON_1948_ENTROPY}. The proportion within an alignment column of each amino acid $i$ of the $K$ = 20 naturally occurring amino acids is denoted by $p_i$. The Shenkin Score, $V_{Shenkin}$, described in \autoref{eq:shenkin}, measures divergence and increases as amino acid variability grows within a column. In a fully conserved position, where all amino acids are the same, entropy is minimum ($S$ = 0) and so is divergence ($V_{Shenkin}$ = 6). Conversely, in a fully variable position, where all amino acids are equally represented, entropy is maximum ($S \approx$ 4.32) and so is divergence ($V_{Shenkin}$ = 120). Utgés \textit{et al.} \cite{UTGES_2021_ANKS} defined a version of this score, $N_{Shenkin}$ (\autoref{eq:shenkin_norm}), which normalises the original score by the minimum and maximum scores within the alignment and ranges 0-100.

\begin{equation}
S = - \sum_{i=1}^{K} p_i \log_2(p_i)
\label{eq:entropy_shannon2}
\end{equation}
\myequations{Shannon's Entropy}

\begin{equation}
V_{Shenkin} = 2^S \times 6
\label{eq:shenkin}
\end{equation}
\myequations{Shenkin divergence score}

\begin{equation}
N_{Shenkin} = \frac{V_{Shenkin} - V_{Shenkin_{\text{min}}}}{V_{Shenkin_{\text{max}}} - V_{Shenkin_{\text{min}}}}
\label{eq:shenkin_norm}
\end{equation}
\myequations{Normalised Shenkin divergence score}

Beyond illuminating the evolutionary history of protein sequences, amino acid conservation patterns derived from alignments have been used to successfully predict a variety of features such as secondary structure elements \cite{ROST_1993_SSPRED}, solvent accessibility \cite{ROST_1994_RSAPRED}, protein-protein interfaces \cite{LICHTARGE_1996_PPIs}, protein-ligand binding sites \cite{GLASER_2006_PREDICTION} and inter-residue contacts \cite{MARKS_2011_CONS} which recently has lead to a breakthrough in the prediction of protein 3D structure \cite{JUMPER_2021_ALPHAFOLD}. There is immense power in the analysis of amino acid conservation, and in this Thesis, the normalised Shenkin divergence score is employed in a systematic manner to rank ligand binding sites on likelihood of function and highlight key residues within them. 

\subsection{Protein structure}

The arrangement in three-dimensional space of protein atoms is known as protein structure. Protein structure can be defined at four different levels (\autoref{fig:protein_structure}). The primary structure of a protein corresponds to the sequence of amino acids forming the polypeptide chain from the first residue in the amino terminus (N-term) to the last one in the carboxyl terminus (C-term) (\autorefpanel{fig:protein_structure}{ A}). Protein residues adopt local sub-structures by the formation of hydrogen bond interactions between the residue backbone atoms. These local conformations are referred to as secondary structure (\autorefpanel{fig:protein_structure}{ B}). There are two main types of secondary structure: α-helix and β-sheets \cite{PAULING_1951_SS}. The absence of any of these structures could be defined as a third structure named coil or loop. Tertiary structure is the three-dimensional structure created by a single polypeptide chain which results from the process of protein folding (\autorefpanel{fig:protein_structure}{ C}). Tertiary structure is defined by the burial of hydrophobic residues in the protein core and hydrogen bonds, salt bridges and disulfide bonds ensuring a tight packing of residue side chains. Finally, quaternary structure results from the aggregation of two or more individual protein chains that come together to form the functional unit of the protein or multimer (\autorefpanel{fig:protein_structure}{ D}). These monomers are held together by the same non-covalent interactions that stabilise tertiary structure. Quaternary structure can present different architectures depending on the number of copies involved: two copies (dimer), three (trimer), four (tetramer) and whether these copies are from the same sequence (homomers) or different ones (heteromers).

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_INTRO/PNG/protein_structure.png}
    \caption[Protein structure]{\textbf{Protein structure.} Four levels of protein structure: primary (\textbf{A}); secondary (\textbf{B}); tertiary (\textbf{C}); quaternary (\textbf{D}). Blue dashed cylinders illustrate hydrogen bonds holding together the secondary structures of α-helix and β-sheets. Example is PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/8dhv}{8DHV} \cite{LIETZAN_2023_BETAGLUCO} of β-glucuronidase of \textit{Treponema lecithinolyticum} (\href{https://www.uniprot.org/uniprotkb/A0AA82WPE8/entry}{A0AA82WPE8}). Structure visualisation with ChimeraX \cite{PETTERSEN_2021_CHIMERAX}.}
    \label{fig:protein_structure}
\end{figure}

\vspace{-13pt} % Adjust this value as needed

\subsection{Protein structure determination}

Protein structure determination is the process of deciphering the arrangement of protein atoms in three-dimensional space. In 1958 Kendrew \textit{et al.} \cite{KENDREW_1958_MYOGLOBIN} resolved the first protein structure for sperm whale myoglobin (\href{https://www.uniprot.org/uniprotkb/P02185/entry}{P02185}) using X-ray crystallography \cite{BERNAL_1934_XRAY}. Apart from X-ray crystallography, nuclear magnetic resonance spectroscopy and more recently cryogenic electron microscopy have also been used extensively for 3D structure determination.

\subsubsection{X-ray crystallography}

The first step to resolve a protein structure using X-ray crystallography (XRC) is to obtain the protein crystal. A protein crystal is a highly ordered structure in which protein atoms are arranged in a repeating uniformly distributed pattern known as crystal lattice. Crystallising a protein can be very time consuming since the optimal conditions vary between proteins with different size, solubility or isoelectric point. Once the crystal is obtained, it is placed on an X-ray beam which will scatter the electron clouds of the atoms generating a diffraction pattern. This pattern can then be transformed to generate an electron density map revealing the position of atoms within the crystal \cite{FRIEDRICH_1913_XRAY, BRAGG_1913_XRAY}. X-ray crystallography provides high-resolution structural information and is accordingly the most widely used method to determine protein structure accounting for $\approx$83\% of structures deposited in the Protein Data Bank (PDB) \cite{BERMAN_2000_PDB}.

\subsubsection{Nuclear magnetic resonance spectroscopy}

Nuclear magnetic resonance spectroscopy (NMR) is a powerful technique to determine 3D structure in solution. It was first used in 1984 by Williamson \textit{et al.} \cite{WILLIAMSON_1985_NMR} to determine the structure of proteinase inhibitor IIA from bull (\href{https://www.uniprot.org/uniprotkb/P01001/entry}{P01001}). NMR does not require a protein crystal, but instead a high concentration of protein in aqueous solution \cite{WUTHRICH_1982_NMR}. NMR relies on the magnetic moment or spin of certain isotopes such as \textsuperscript{1}H, \textsuperscript{13}C or \textsuperscript{15}N. In the presence of a magnetic field, the application of radio frequency pulses to these isotopes results in a chemical shift that is diagnostic of their local electronic environment and recorded as the NMR spectrum. The chemical shifts in the spectrum are assigned to individual atoms and distance, angle and orientation restraints are derived. This information is integrated to calculate a model that is then refined to yield the final structure \cite{WUTHRICH_1984_NMR}. NMR is ideal to study the dynamics of proteins or other molecules in solution. However, NMR often results in lower structure resolution and its use is limited to smaller proteins as the spectra get more complex with increasing protein size \cite{EMWAS_2015_NMR}.

\subsubsection{Cryogenic electron microscopy}

The use of electron microscopy to determine protein structure dates back to 1975 \cite{HENDERSON_1975_EM} but modern cryogenic electron microscopy (Cryo-EM) was not used to resolve a protein structure until 1990 when Henderson \textit{et al.} \cite{HENDERSON_1990_CRYOEM} determined the structure of \textit{Halobacterium halobium} bacteriorhodopsin (\href{https://www.uniprot.org/uniprotkb/P02945/entry}{P02945}). In Cryo-EM, proteins are rapidly frozen to very low temperatures to preserve their native state. The frozen sample is then put under an electron microscope which will generate a set of two-dimensional projections from the electron beams. These projections are later integrated into a 3D model. Cryo-EM tends to provide lower resolution than X-ray or NMR, however is the only method that can determine the structure of large macromolecular complexes such as the spliceosome \cite{CHUANGYE_2016_SPLICEOSOME} or the nucleopore \cite{KOSINSKI_2016_NUCLEOPORE}. This resolution limitation was breached in the last decade when Bartesaghi \textit{et al.} \cite{BARTESAGHI_2014_CRYOEM} reached a resolution of 3.2 \AA{} for \textit{Escherichia coli} β-galactosidase (\href{https://www.uniprot.org/uniprotkb/P00722/entry}{P00722}). While XRC has decades of advantage over Cryo-EM in terms of deposited structures, due to the rapid advances in the latter method, it is projected that the number of depositions between these two methods will coalesce by the year 2035 \cite{CHIU_2021_CRYOEM}.

\subsection{Protein structure characterisation}

Beyond the determination of the arrangement of atoms in three-dimensional space, proteins can be characterised structurally in multiple ways that offer insight into their physicochemical properties, their stability, dynamics and interaction with other molecules. These features can then be mapped onto the molecular surface of the proteins and visually analysed (\autoref{fig:protein_features}).

\subsubsection{Flexibility}

The Debye-Waller factor (DWF), or B-factor, measures the attenuation of X-ray scattering caused by thermal motion \cite{DEBYE_1913_BFACTOR, WALLER_1923_BFACTOR}. This attenuation is a decrease of intensity in diffraction caused by disorder. This disorder can be dynamic and result from the temperature-dependent vibration of the atoms, or static \cite{SUN_2019_BFACTOR}. Accordingly, low values of B-factor indicate rigid or well-ordered protein regions, while high values can identify flexible or dynamic regions in proteins such as loops or binding sites as well as intrinsically disordered regions (IDR) (\autorefpanel{fig:protein_features}{ A}). IDRs are protein regions that lack a determined three-dimensional structure and might change conformation depending on their biological context.

\subsubsection{Hydrophobicity}

The molecular lipophilicity potential (MLP) is a descriptor that represents the spatial distribution of lipophilicity across the surface of a molecule and provides insight into how hydrophobic or hydrophilic different regions of a molecule are based on the chemical nature of their atoms \cite{BROTO_1984_MLP, LAGUERRE_1997_MLP}. High MLP values correspond to lipophilic (hydrophobic) areas and lower MLP values correlate to less lipophilic (more hydrophilic) regions (\autorefpanel{fig:protein_features}{ B}). The analysis of protein lipophilicity is relevant for the identification of hydrophobic pockets where lipophilic ligands are likely to bind, allosteric sites, large hydrophobic patches prone to protein aggregation, as well as for protein and enzyme engineering \cite{EFREMOV_2007_MLP}. Analysing the lipophilicity of small molecules is also very relevant for optimising ligand design and improving drug absorption, permeability or solubility \cite{GAILLARD_1994_MLP}.

\subsubsection{Charge}

Amino acid with charged side chains, e.g., Asp, Glu, His, Lys and Arg, play an important role in the electrostatic potential of a protein, which can be calculated using Coulomb's law \cite{COULOMB_1785_LAW}. Electrostatic potential plays a pivotal role in the field of protein analysis as it underpins processes such as protein folding, enzyme catalysis and molecular recognition and interaction with proteins, nucleic acids and small molecules, or ligands \cite{ZHOU_2018_ESP} (\autorefpanel{fig:protein_features}{ C}). Because of this, protein electrostatics analysis and fine-tuning has applications in protein design \cite{GORHAM_2011_ESP}, protein-ligand binding affinity \cite{KUKIC_2010_ELECTROSTATICS} and biocatalysis optimisation \cite{VASCON_2020_ESP}.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_INTRO/PNG/protein_features.png}
    \caption[Protein structure features]{\textbf{Protein structure features.} Protein structure features exemplified on PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/4c38}{4C38} \cite{COUTY_2013_ONCO} of bovine cAMP-dependent protein kinase catalytic subunit alpha (\href{https://www.uniprot.org/uniprotkb/P00517/entry}{P00517}). \textbf{(A)} Atomic displacement measured by Debye-Waller factor (DWF); \textbf{(B)} Hydrophobicity measured by molecular lipophilicity potential (MLP); \textbf{(C)} Charge measured by Coulombic electrostatic potential (ESP); \textbf{(D)} Accessibility measured by relative solvent accessibility (RSA); \textbf{(E)} Ligandability as measured by P2Rank's ligandability score. Structure visualisation with ChimeraX \cite{PETTERSEN_2021_CHIMERAX}.}
    \label{fig:protein_features}
\end{figure}

\subsubsection{Accessibility}

The surface area of a biomolecule that is accessible to solvent is known as accessible surface area (ASA) or solvent-accessible surface area (SASA). ASA was first described by Lee and Richards in 1971 \cite{LEE_1971_ASA} and is usually calculated using the ``rolling ball'' algorithm described by Shrake and Rupley \cite{SHRAKE_1973_ASA}. The van der Waals (VDW) surface of a molecule is defined by the VDW radii of the atoms forming it \cite{1873_VANDERWAALS_VDW}. In their algorithm, Shrake and Rupley draw a mesh of points equidistant to each atom on the molecule. These points are typically drawn at a distance of 1.4 \AA{}, emulating the radius of a water molecule, i.e., solvent. By \textit{rolling} this spherical probe over each atom, they established whether a mesh point was exposed to the solvent or buried and calculated the individual contribution of each atom or residue to the ASA of a protein (\autorefpanel{fig:protein_features}{ D}). The ASA of a molecule is then the path traced by the centre of the spherical probe rolled over the VDW surface. Years later, Richards \cite{1977_RICHARDS_SSE} defined the molecular or solvent-excluded surface (SES) which results from the trajectory of the outer edge of the sphere probe and has two components: the contact surface and the \textit{reentrant} surface. The contact surface is the part of the VDW surface that is in direct contact with the probe. The reentrant surface is an inward-facing or concave surface resulting from the contact of the probe with multiple atoms (\autoref{fig:molecular_surfaces}). Conolly was the first to implement algorithms for the analytical calculation of the SES \cite{1983_CONNOLLY_SASA, 1983_CONNOLLY_SASA2}.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_INTRO/PNG/molecular_surfaces.png}
    \caption[Molecular surfaces]{\textbf{Molecular surfaces.} Different definitions of the surfaces of a molecule including Van der Waals surface of atoms, solvent accessible surface defined area by Richards and Lee and solvent-excluded surface by Richards with its two components: reentrant and contact surfaces. Adapted from the ChimeraX website \cite{surface_diagram}.}
    \label{fig:molecular_surfaces}
\end{figure}

The SASA measured for a given residue in a protein structure is an absolute measure and is not directly comparable across amino acids due to the different chemistry and size of their side chains. There are multiple scales to carry out this normalisation and all of them have been obtained using Gly-$X$-Gly tripeptides, where $X$ represents each of the twenty amino acids \cite{1985_ROSE_MAXASA, MILLER_1987_MAXASA, TIEN_2013_RSA}. These scales assume that on this tripeptide construct, located in between two glycines at the N- and C-termini, amino acid side chains can adopt an extended conformation and achieve their maximum ASA (MaxASA). A relative solvent accessibility (RSA) can then be obtained by dividing the ASA by the maximum allowed accessible surface area for a given residue as shown in \autoref{eq:RSA}.

\begin{equation}
\text{RSA} (\%) = 100 \times \text{ASA}/\text{MaxASA}
\label{eq:RSA}
\end{equation}
\myequations{Relative solvent accessibility}

\vspace{-13pt} % Adjust this value as needed

The analysis of the solvent accessibility landscape of proteins provides rich insight into protein evolution, function, stability and folding. RSA can classify residues into buried and accessible to solvent. Residues with low RSA tend to be buried in the core of the protein and form a network of hydrophobic interactions that ensure the correct packing of the protein \cite{DILL_1990_FOLDING}. Residues with high RSA are on the surface and interact with solvent and other biomolecules. Accordingly, RSA can be used to identify active sites and hotspot residues that are key contributors to the binding interaction with ligand or protein partners \cite{JONES_1997_PROTINTERS}. Active sites tend to have intermediate RSA values (20-50\%) since they need to be accessible enough to bind to their substrates but also partially protected to allow for a stable substrate binding and catalysis. Additionally, solvent accessibility is known to be correlated with evolutionary conservation \cite{GOLDMAN_1998_SS_RSA_EVO}. Residues buried in the hydrophobic core are conserved through evolution as mutations in them have a destabilising effect and can lead to protein misfolding and aggregation.

In \autoref{chap:FRAGSYS} and \autoref{chap:LIGYSIS_WEB}, ASA is calculated with DSSP \cite{KABSCH_1983_DSSP} and normalised using the method of Tien \textit{et al.} \cite{TIEN_2013_RSA} to characterise the solvent accessibility profile of ligand binding sites and predict their likelihood of function.

\subsubsection{Ligandability}

Ligandability is the ability of a residue, set of residues or protein to bind a small molecule or ligand. Ligands play a critical role in protein function acting as natural co-factors, substrates, inhibitors and drugs in disease therapy (\autoref{fig:small_molecules}). Identifying where ligands can bind to proteins is therefore of critical importance in understanding and modulating protein function. While X-ray crystallography remains the gold-standard to identify and characterise binding sites \cite{REES_2004_FBLD}, over the last three decades, significant effort has been made to develop computational methods that predict binding sites from an apo three-dimensional protein structure \cite{VOLKAMER_2010_TOPOLOGY}. Ligandability can be calculated by methods like P2Rank \cite{KRIVAK_2018_P2RANK} as the probability of an atom or residue binding to a ligand and then visualised on a protein surface (\autorefpanel{fig:protein_features}{ E}).

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_INTRO/PNG/small_molecules.png}
    \caption[Protein-ligand complexes]{\textbf{Protein-ligand complexes.} Small molecule ligands interact with proteins and act as cofactors, substrates, inhibitors and drugs for therapeutic treatment. \textbf{(A)} Cytochrome P450 2C9 (\href{https://www.uniprot.org/uniprotkb/P11712/entry}{P11712}) interacting with haem (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/HEM}{HEM}) as a cofactor. PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/7RL2}{7RL2} \cite{PARIKH_2021_CYTOP450}; \textbf{(B)} Glutathione S-transferase A3 (\href{https://www.uniprot.org/uniprotkb/Q16772/entry}{Q16772}) interacting with its substrate glutathione (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/GSH}{GSH}). PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1tdi}{1TDI} \cite{GU_2004_GST}; \textbf{(C)} Dual specificity tyrosine-phosphorylation-regulated kinase 2 (\href{https://www.uniprot.org/uniprotkb/Q92630/entry}{Q92630}) interacting with a natural inhibitor curcumin (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/CC9}{CC9}). PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/6hdr}{6HDR} \cite{PDB_6HDR}; \textbf{(D)} Sodium-dependent serotonin transporter (\href{https://www.uniprot.org/uniprotkb/P31645/entry}{P31645}) binding to paroxetine (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/8PR}{8PR}) which is an antidepressant. PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5i6x}{5I6X} \cite{COLEMAN_2016_PAROXETIN}.}
    \label{fig:small_molecules}
\end{figure}

Methods that predict ligand binding sites exploit a variety of different techniques to suggest binding sites. Geometry-based techniques like fpocket \cite{GUILLOUX_2009_FPOCKET}, Ligsite \cite{HENDLICH_1997_LIGSITE} and Surfnet \cite{LASKOWSKI_1995_SURFNET} identify cavities by analysing the geometry of the molecular surface of a protein and usually rely on the use of a grid, gaps, spheres, or tessellation \cite{GUILLOUX_2009_FPOCKET, LIANG_1998_CAVITIES, HENDLICH_1997_LIGSITE, LASKOWSKI_1995_SURFNET, KLEYWEGT_1994_CAVITIES, LEVITT_1992_POCKET, BRADY_2000_PASS, WEISEL_2007_POCKETPICKER}. Energy-based methods such as PocketFinder \cite{AN_2005_POCKETFINDER} rely on the calculation of interaction energies between the protein and a chemical group or probe to identify cavities \cite{AN_2005_POCKETFINDER, GOODFORD_1982_PREDICTOR, AN_2004_PREDICTOR, LAURIE_2005_QSITEFINDER, GHERSI_2009_SITEHOUND, NGAN_2012_FTSITE}. Conservation-based methods make use of sequence evolutionary conservation information to find patterns in multiple sequence alignments and identify conserved key residues for ligand site identification \cite{ARMON_2001_CONSURF, PUPKO_2002_RATE4SITE, XIE_2012_CONSPRED}. Template-based methods rely on structural information from homologues and the assumption that structurally conserved proteins might bind ligands at a similar location \cite{ZVELEBIL_1987_PREDICTION, WASS_2010_3DLIGANDSITE, ROY_2012_COFACTOR, YANG_2013_COFACTOR, LEE_2013_PREDICTION, BRYLINSKI_2013_EFINDSITE}. Combined approaches or meta-predictors combine multiple methods, or the use of multiple types of data, to infer ligand binding sites, e.g., geometric features with sequence conservation \cite{GUTTERIDGE_2003_LBSP, HUANG_2006_BU48, GLASER_2006_PREDICTION, HALGREN_2009_PREDICITON, CAPRA_2009_CONCAVITY, HUANG_2009_METAPOCKET, BRAY_2009_SITESIDENTIFY, BRYLINSKI_2009_FINDSITE}. Finally, machine learning methods utilise a wide range of machine learning techniques including random forest, as well as deep, graph, residual, or convolutional neural networks \cite{KRIVAK_2015_PRANK, KRIVAK_2015_P2RANK, JIMENEZ_2017_DEEPSITE, KRIVAK_2018_P2RANK, SANTANA_2020_GRaSP, KOZLOVSKII_2020_BITENET, STEPNIEWSKA_2020_KALASANTY, KANDEL_2021_PURESNET, MYOLNAS_2021_DEEPSURF, YAN_2022_POINTSITE, LI_2022_RECURPOCKET, AGGARWAL_2022_DEEPPOCKET, ABDOLLAHI_2023_NODECODER, EVTEEV_2023_SITERADAR, LI_2023_GLPOCKET, ZHANG_2024_EQUIPOCKET, LIU_2023_REFINEPOCKET, SMITH_2024_GrASP, CARBERY_2024_IFSP, SESTAK_2024_VNEGNN, KANDEL_2024_PURESNET}.

\autoref{chap:LBS_COMP} and \autoref{chap:LBS_IMPROV} describe the largest benchmark of ligand binding site prediction to date by analysing the performance of thirteen methods using a series of metrics on a brand new reference dataset described in \autoref{chap:LIGYSIS_WEB}.

\subsection{Databases}

There are many databases providing relevant information for protein analysis but two of the most commonly used ones and extensively employed in this Thesis are UniProt and the Protein Data Bank (PDB).

\subsubsection{UniProt}

UniProt is a comprehensive protein sequence database including cross-references to multiple resources to provide a wealth of information about gene expression, pathogenic variation, post-translational modifications (PTMs), protein-protein interactions, domain annotations and three-dimensional structure amongst others \cite{BAIROCH_2005_UNIPROT}. It is conformed by two main components: SwissProt and TrEMBL. SwissProt is manually curated and includes 600 thousand high-quality sequences often referred to as \textit{reviewed}. TrEMBL on the other hand catalogues over 250 million \textit{unreviewed} protein sequences resulting from the automatic translation of coding sequences found in the main nucleotide databases \cite{BAIROCH_2000_UNIPROT}.

\subsubsection{Protein Data Bank}

The Protein Data Bank is a worldwide repository for the three-dimensional structures of biological macromolecules such as proteins, DNA and RNA. There are currently 230 thousand 3D structures deposited in the archive determined mainly through X-ray crystallography, NMR spectroscopy and Cryo-EM \cite{BERMAN_2003_PDB}. Through resources such as the Protein Data Bank Europe (PDBe) knowledgebase, or PDBe-KB, three-dimensional structure is linked to functional annotations including that of domains, predicted disorder, ligand binding sites or PTMs \cite{PDBEKB_2019_PDBEKB}.

\section{Genetic variation}

Genetic variation is the difference in DNA sequence between individuals or populations of the same species. The main source of genetic variation is \textit{de novo} mutation. Mutations are changes in a genetic sequence that usually arise during DNA replication due to errors made by the imperfect replication machinery. Mutation can also occur as a result of damage to DNA, e.g., ultraviolet radiation, or during the repair process of such damage. Genetic variation can affect a single nucleotide in the sequence, i.e., a single nucleotide polymorphism (SNP), or multiple nucleotides (MNP), or larger DNA regions, even entire chromosomes, e.g., insertion, deletion, translocation, or fusion. SNPs are the only type of genetic variation relevant for the research described in this Thesis.

\subsection{Types of genetic variation}

\subsubsection{Genomic location}

Based on genomic location, genetic variation can be classified into \textit{coding} variation if it affects the mRNA that codes for the protein sequence. Alternatively, \textit{non-coding} variants are those that affect other regions that do not code for a protein product, such as introns, intergenic regions, promoters, enhancers or other regulatory elements.

\subsubsection{Effect on coding sequence}

The genetic code is \textit{degenerate} or redundant, as there are 4 $\times$ 4 $\times$ 4 = 64 codons coding for only twenty amino acids. For this reason, a change in the coding DNA sequence is not always reflected in the protein sequence. Mutations that due to the redundancy in the genetic code do not alter the protein sequence are called synonymous or silent. Nonsynonymous mutations \textit{do} change the protein sequence and can be further classified into: missense, nonsense, nonstop and frameshift mutations. Missense mutations are those that replace one of the twenty amino acids by a different one. Missense variants can be conservative, if the interchanged residues present similar physicochemical properties, e.g., leucine $\rightarrow$ isoleucine, or they can be non-conservative or radical if the exchanged amino acids are biochemically different, e.g., lysine $\rightarrow$ threonine. Nonsense mutations replace one of the twenty amino acids by one of the three STOP codons, resulting in an early termination of the peptide chain. Nonstop variants are the exact opposite and exchange the original stop codon by one of the twenty amino acids thus resulting in an abnormally elongated protein. Finally, frameshift mutations result from the insertion or deletion of nucleotides that are not a multiple of three. When this happens, the frame on which the translation machinery reads the mRNA is shifted and a completely different protein product is obtained.

While missense mutations, which simply replace one amino acid by another and can be conservative, have a limited effect on protein sequence and structure, nonsense, nonstop and frameshift mutation have more drastic consequences. Because of this, missense variants tend to be more tolerated and are observed with higher frequency in the general population \cite{COULTER_2004_MUTATIONS}.

\subsubsection{Impact on phenotype}

Genetic variants can also be classified based on the effect they have on the phenotype, or clinical significance, which usually corresponds to an effect on the concentration, structure, function or activity rate of a protein \cite{VIHINEN_2022_VARIATION}. Mutations that do not have a harmful effect on the protein are called neutral or benign. Since neutral variants have no noticeable effect on the \textit{fitness} \cite{DARWIN_1859_ORIGIN}, i.e., the ability to leave offspring, they are not under selective pressure and consequently roam around in the general population \cite{KIMURA_1968_NEUTRAL}. Conversely, pathogenic variants disrupt biological processes and eventually result in disease. Disease severity will dictate the strength with which natural selection acts upon the causing variant and therefore its frequency in the population. Mutations affecting genes needed for development and survival, or essential genes, might have lethal effects and never be observed in the population \cite{GLUECKSOHN_1963_LETHALITY}.

It is estimated that only 2\% of the more than 4 million observed human missense variants have been clinically classified as pathogenic or benign \cite{LEK_2016_EXAC}. Variants of unknown significance (VUS) therefore represent the vast majority of observed missense variants and the prediction of their effect on fitness is an important ongoing challenge in human genetics \cite{MCLAREN_2016_VEP}. Several methods exploiting different technologies have been developed over the years to tackle this challenge with SIFT \cite{KUMAR_2009_SIFT}, PolyPhen \cite{ADZHUBEI_2013_POLYPHEN} and the recent AlphaMissense \cite{CHENG_2023_ALPHAMISSENSE} being some of the most relevant ones.

\subsection{Variation is constrained}

Since the sequencing of the first draft of the human genome in 2001 \cite{CONSORTIUM_2001_GENOME}, several massively parallel methods have been developed for the high-throughput sequencing of nucleic acids \cite{KASIANOWICZ_1996_NANOPORE, MARGULIES_2005_PYROSEQUENCING, BENTLEY_2008_ILLUMINA, EID_2009_PACBIO, ROTHBERG_2011_IONTORRENT}. The drastic reduction in both time and cost required to sequence DNA has enabled large-scale projects such as the 1000 Genomes Project \cite{AUTON_2015_1000KG} or UK Biobank \cite{BYCROFT_2018_UKBIOBANK}. Resources like the genome aggregation database (gnomAD), a comprehensive resource for human genetic variation aggregating data from over 140,000 genomes and exomes, make it possible to carry out large-scale comparative analysis to understand the distribution of genetic variation along the human genome.

In a similar way as protein sequence is constrained across species resulting in patterns of amino acid conservation in multiple sequence alignments, the genomic distribution of genetic coding variation within the human species is also constrained by factors such as protein structure and function. Several studies have demonstrated that functional elements like buried core residues, catalytic residues in enzymatic active sites and protein-protein interaction interfaces are strongly constrained and present fewer variants than observed elsewhere in the protein \cite{GONG_2010_CONSTRAINT, BEER_2013_CONSTRAINT, DAVID_2015_CONSTRAINT, SIVLEY_2018_CONSTRAINT}. This phenomenon is a consequence of purifying or negative natural selection acting upon the population. Variants occurring at these functional sites are likely to impair protein function and they are therefore removed from the gene pool resulting in a lower mutational burden, or \textit{depletion} in variation, at these positions. By quantifying these evolutionary signals, functional constraint can be measured at the genic \cite{PETROVSKI_2013_CONSTRAINT} and domain \cite{GUSSOW_2016_CONSTRAINT} levels and used for the functional interpretation of variants of unknown significance \cite{LI_2022_CONSTRAINT}. Despite the wealth of variation data available that allows for gene- and domain-level quantification of variation constraint, doing so at the individual residue level remains a challenge.

\subsection{Missense enrichment score}

MacGowan \textit{et al.} approached this issue in their 2017 work \cite{MACGOWAN_2017_VARIANTS} by aggregating variants from human paralogous sequence residues present in the same alignment column. Residues aligning in the same column are homologous, i.e., share a common ancestor, and therefore aggregating their variants to infer residue-level constraint is a fair assumption. They developed a missense enrichmente score (MES) to numerically quantify the evolutionary constraint acting on individual residues, or positions, by leveraging the variants found not just in a protein of interest but also in their human paralogues. For each alignment column $x$, the number of human residues mapping to it were counted ($\text{residues}_x$), as well as the number of human residues mapping to all other columns ($\text{residues}_{other}$). Additionally, the number of variants found across all human residues aligned to the column of interest ($\text{variants}_x$) and all other columns ($\text{variants}_{other}$) were also counted. With these four quantities, the MES can be computed as showed in \autoref{eq:MES}. These four values can also be arranged in a 2 $\times$ 2 contingency table and the MES understood as an odds ratio (OR) expressing the likelihood of observing variants in column $x$ relative to all other alignment columns. An OR > 1 means a column presents more variants than the average of all other columns, i.e., is \textit{enriched} in missense variants, whilst an OR < 1 indicates \textit{depletion} relative to the rest of the alignment. An OR = 1 indicates neutrality relative to the other columns, i.e., the number of variants found within column $x$ follows the same distribution as the average of the rest of the alignment. Using Fisher's exact test \cite{FISHER_1935_TEST} the significance of this MES (OR) can be assessed with a $p$-value.

\begin{equation}
\text{MES} = \frac{\text{variants}_x / \text{residues}_x}{\text{variants}_{other} /\text{residues}_{other}}
\label{eq:MES}
\end{equation}
\myequations{Missense enrichment score}

\vspace{-13pt} % Adjust this value as needed
\vspace{-13pt} % Adjust this value as needed

\subsection{Conservation plane}

Both Shenkin and MES are measures of evolutionary constraint on protein amino acids. Nevertheless, these metrics quantify it at two completely different time scales. Amino acid divergence calculated from an MSA captures the evolutionary history of a protein family resulting of hundreds of millions of years of divergence across species originated from speciation events, large-scale genomic rearrangements and strong selective pressures, among other factors. In contrast, the missense enrichment score aims to capture the variability in our species emerging from migration events, genetic drift and weaker selection taking place within a much shorter time scale \cite{HUBLIN_2017_HUMAN}. The stratification of conserved and divergent positions by MES yields four classifications, or four quadrants of the \textit{conservation plane} (\autoref{fig:conservation_plane}). These are conserved positions that are missense-depleted (CMD), conserved positions, yet enriched in missense variation (CME), unconserved, or divergent, positions enriched in missense variants (UME) and unconserved and missense-depleted (UMD) positions \cite{MACGOWAN_2024_VARIANTS}.

CMD positions are the most constrained both across species (conserved) and within the human population (missense-depleted). The vast majority of them are buried in the core and are critical for protein folding, packing and stability. When they are not buried, they are highly enriched in protein-protein and protein-ligand interactions \cite{UTGES_2021_ANKS}. Additionally, they are enriched in ClinVar \cite{LANDRUM_2013_CLINVAR} pathogenic variants, further emphasising their relevance. Unconserved positions are often dismissed as they appear to be mutating freely and be under no constraint, resulting in their divergence across homologues. However, MacGowan and colleagues \cite{MACGOWAN_2024_VARIANTS} showed that there is a subset of unconserved positions that are strongly constrained in the human population, i.e., significantly depleted in missense variation. These positions tend to be on the surface and act as specificity-determining positions (SDP) bestowing protein domains the ability to bind a wide range of substrates. Furthermore, they are enriched in pathogenic variants relative to their missense-enriched counterpart (UMEs).

\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.55\textwidth]{figures/ch_INTRO/PNG/conservation_plane.png}
    \caption[Conservation plane]{\textbf{Conservation plane.} The \textit{conservation plane} arises from the comparison of within-species constraint, as measured by the missense enrichment score (MES), and across-species constraint quantified by amino acid conservation, in this case, by a normalised Shenkin divergence score. The conservation plane can be divided in four quadrants. Positions that are conserved across species and missense-depleted in human (CMD) are found in the bottom-left corner (pink). Conserved positions that are enriched in missense variation (CME) are on the top-left quadrant (green). Unconserved or divergent positions enriched in missense variants (UME) are on the top-right (blue). Finally, unconserved and missense-depleted (UMD) positions are on the bottom-right (orange). Borrowed from MacGowan \textit{et al.} \cite{MACGOWAN_2024_VARIANTS}.}
    \label{fig:conservation_plane}
\end{figure}

\vspace{-13pt} % Adjust this value as needed
\vspace{-13pt} % Adjust this value as needed

\section{Drug discovery}

Drug discovery is the process of developing a new drug. It goes from the original idea conception to the market launch of a finished product and beyond. This is an extremely complex process which can take up to 12-15 years and cost more than \$1 billion \cite{HUGHES_2011_DRUGS}. This high economic and time cost is caused by the high rate of failure that potential drug candidates experience during the development process, also known as \textit{attrition}. The drug discovery and development pipeline is illustrated in \autoref{fig:drug_discovery}. This pipeline can be divided in two stages. Stage I is drug discovery and encompasses target identification and validation, hit identification and lead optimisation. Stage II corresponds to the development of the drug and includes pre-clinical, clinical trials and drug approval.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_INTRO/PNG/drug_discovery.png}
    \caption[Drug discovery and development pipeline]{\textbf{Drug discovery and development pipeline.}  The pipeline for discovering a drug can be divided in two stages. Stage I focuses on the discovery of a drug and includes target identification and validation, hit identification and lead optimisation. Stage II covers the development of the drug and includes pre-clinical, clinical trials, drug approval and subsequent pharmacovigilance. Adapted from Cui \textit{et al.} \cite{CUI_2020_DRUGS}.}
    \label{fig:drug_discovery}
\end{figure}

\subsection{Target identification}

Target identification is the first step in the drug discovery pipeline and one of the most relevant. Drugs often fail in the clinical stages due to two main reasons: they are not safe or they do not work. Because of this, a thorough target identification and subsequent validation is vital. The goal of this step is to identify a biomolecule to target with a drug to treat or cure a disease. The target can either be a gene, RNA or protein and the drug is usually a small molecule, peptide or a protein, e.g., antibody. An ideal target meets a series of requirements: efficacy, safety and most importantly \textit{druggability}, among others. A \textit{druggable} target is amenable to interact with a putative drug. This interaction should trigger a biological response measurable \textit{in vitro} and \textit{in vivo} through biochemical or functional assays. The mining of available biomedical data from the literature, proteomics, 3D structure, genetic association studies, pathogenic variation or phenotypic screening are some of the most commonly used approaches in target identification \cite{SCHENONE_2013_TARGETID}.

\subsection{Target validation}

Target validation is the technical assessment of whether a target plays a critical role in a disease process and whether pharmacological modulation of the target could be effective in a particular patient population. It is predicted that a more effective target validation strategy could reduce attrition in phase II clinical trials by $\approx$24\% lowering the cost of developing a new molecular entity (NME) by $\approx$30\% \cite{PAUL_2010_RD}. Accordingly, the validation of a therapeutic target is a step of paramount importance within the discovery of new drugs. Some of the most frequently used approaches to validate a target include RNA interference, gene knockouts, the use of animal models and target druggability analysis, e.g., by ligand binding site prediction \cite{EMMERICH_2021_TARGET_VAL}.

\subsection{Hit identification}

The next step once the target has been validated is to identify \textit{hits}. Hits are compounds that bind to the target and elicit the desired biological activity in an assay. Their identification relies on a combination of experimental techniques, e.g., high-throughput (HTS) or fragment screening (FS), and computational techniques such as virtual screening (VS). In high-throughput screening, robotic automation is employed to evaluate large libraries of chemical compounds against a target in a biochemical or cell-based assay. HTS usually identifies a few compounds with the desired biological activity and high binding affinity to the target. FS is complementary to HTS and obtains high-quality information about the 3D structure of the protein-ligand complex by using X-ray crystallography. Lastly, provided the 3D structure of the target is known, virtual screening techniques can be used. VS encompasses a set of ligand-based (LBVS) and structure-based (SBVS) computational techniques, such as pharmacophore-mapping or protein-ligand docking, respectively, that are able to identify hotspot residues relevant for ligand binding and guide the design of more effective compounds \cite{SINHA_2018_DD}.

\subsection{Lead optimisation}

In this phase, identified hits are refined into promising \textit{lead} compounds by optimising their properties before getting to pre-clinical drug candidates. This refinement aims to enhance pharmacokinetic (PK) properties such as potency, i.e., binding affinity to the target, as well as selectivity, by minimising off-target effects, solubility, permeability, stability and toxicity. Quantitative structure-activity relationship (QSAR) studies are carried out to suggest molecules with more favourable PK properties by adding or replacing functional groups of the original hit compound. Additionally, high-throughput \textit{in vitro} assays can be carried out to optimise the absorption (how it enters the bloodstream), distribution (how it travels within the body), metabolism (how it is broken down), excretion (how it is eliminated) and toxicity (ADMET) properties of the compounds \cite{SHOU_2020_ADME}.

\subsection{Pre-clinical studies}

The discovery stage concludes with the obtention of the optimised leads and thus begins the development with pre-clinical studies. The primary goal of this phase is to thoroughly evaluate the safety, efficacy, pharmacokinetics and pharmacodynamics (PD) of the drug candidates before advancing to clinical trials in humans. This is achieved with a combination of \textit{in vitro}, e.g., cell-based assays, and \textit{in vivo}, e.g., animal models, studies. ADMET properties are assessed to ensure a favourable pharmacological profile and toxicology studies are carried out to establish the no observed adverse effect level (NOAEL) and determine a safe starting dosage in human \cite{SHEGOKAR_2020_PRECLINICAL}.

\subsection{Clinical trials}

Those candidates that passed successfully the pre-clinical development will be submitted to clinical trials in voluntary human subjects. Clinical trials are divided in three phases with different goals. Phase I focuses on establishing the maximum tolerated dose (MTD) of a drug by performing strictly calculated dose escalation in a small number (20-80) of \textit{healthy} and \textit{diseased} individuals. Phase II will aim to establish the preliminary efficacy of the drug by comparing a \textit{treatment} and a \textit{placebo} or control group whilst closely monitoring side effects. Usually 100-300 people are involved in Phase II trials. Phase III confirm the safety and efficacy of the drug by involving a larger (1000-3000) and more diverse target population whilst noting potential adverse side effects. Successful completion of clinical trials results in the submission of a comprehensive report to regulatory agencies for review, marking the final step before the drug can reach the market \cite{UMSCHEID_2011_TRIALS}.

\subsection{Drug approval}

Once a drug has been approved and granted license by regulatory agencies such as the Food and Drug Administration (FDA), the European Medicines Agency (EMA) or the Medicines and Healthcare products Regulatory Agency (MHRA), it can be commercialised. Once on the market, drugs enter the post-marketing phase, also known as phase IV. In this stage, pharmacovigilance activities are conducted to monitor long-term safety and effectiveness in larger and more diverse populations. This includes the identification of rare adverse effects and potential new therapeutic uses \cite{SUVARNA_2010_PHASE4}.

\section{Fragment-based drug discovery}

Fragment-based drug discovery (FBDD), or fragment screening, is a widely used technique to identify compounds binding against a specific protein target \cite{MURRAY_2009_FBDD}. It falls within the range of tools used in the hit identification step of the drug discovery pipeline. FBDD typically uses X-ray crystallography to provide detailed information on the binding mode of small molecule fragments that bind to a protein \cite{REES_2004_FBLD}. These fragments explore the vast chemical space and usually obey the \textit{Rule of 3}: they present low molecular weight (200-500 Da), few rotatable bonds and low hydrophobicity \cite{CONGREVE_2003_RO3}. Hits tend to have low affinity (milimolar range) due to their small size. Nevertheless, they provide a good scaffold for optimisation and can be linked or grown to form more potent leads \cite{SCHIEBEL_2016_FRAGMENTS}. A typical fragment screening experiment generates a collection of three-dimensional structures with fragments bound to different regions of the protein. This is done by soaking pre-formed protein crystals in high-concentration fragment solutions, allowing the fragments to bind to the protein. After soaking, crystals are carefully washed to remove unbound fragments and cryoprotected before freezing. Once frozen, fragment-bound crystals are X-rayed, electron densities analysed and structure models obtained \cite{PATEL_2014_FS}.

While many fragments group around well understood catalytic or binding sites, fragments are also observed bound to regions of the protein where the functional significance is unclear. Such sites may be functionally irrelevant or could identify previously unknown allosteric or other functionally important sites worthy of experimental investigation.

\section{Thesis scope}

The UniProt knowledgebase (UPKB) catalogues 248 million protein sequences \cite{UNIPROT_2018_UNIPROT, UNIPROT_2023_UNIPROT}. The sequence-to-structure gap has been significantly reduced thanks to recent developments in the prediction of protein 3D structure \cite{ABRAMSON_2024_ALPHAFOLD3} and structure models for most of these proteins are available through resources such as the AlphaFold Database \cite{VARADI_2022_ALPHAFOLDDB} and other providers \cite{GUEX_2009_SWISSMODEL, BEIENERT_2016_SWISSMODEL, WATERHOUSE_2018_SWISSMODEL}. However, only a small fraction of these proteins present residue-level functional annotations in UniProt -- 55 thousand (0.02\% of UPKB) or include biologically relevant ligands co-crystallised in the PDB \cite{wwPDB_2019_PDB} -- 29 thousand (0.01\%) \autoref{fig:data_explosion}. The significant expense and time required for experimental validation underscores an urgent need for computational methods to characterise ligand sites systematically and highlight residues likely to be relevant to protein function.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.55\textwidth]{figures/ch_INTRO/PNG/data_explosion.png}
    \caption[Database growth curves]{\textbf{Database growth curves.}  Growth curves for some of the most relevant nucleotide and protein sequence and structure databases from 1970 to date. The European Nucleotide Archive (ENA) catalogues nucleotide sequences \cite{LEINONEN_2010_ENA}. ModBase, ModelArchive and AlphaFold DB are some of the largest predicted protein structure resources. UniProt-KB\textsubscript{FUNC} corresponds to the subset of protein sequences with residue-level experimentally determined functional annotations. BioLiP is a semi-curated database of biologically relevant protein-ligand complexes \cite{YANG_2013_BIOLIP}. SWISS-MODEL was not included in this graph as growth curves could not be obtained. Likewise for ENA, for which just the number of sequences in 2024 is included. Y-axis is in log\textsubscript{10} scale.}
    \label{fig:data_explosion}
\end{figure}

Small molecule ligands are crucial for protein function acting as substrates, cofactors as well as drugs in therapy. Identifying the protein regions where these molecules bind, understanding the mode in which they do so and characterising that interface is therefore key to understanding and modulating protein function. This Thesis describes work for the definition, characterisation and classification of likely functional class of ligand binding sites derived from fragment screening experiments \autoref{chap:FRAGSYS}. \autoref{chap:LIGYSIS_WEB} extends this approach to the entirety of the PDBe, characterising $>$65,000 biologically relevant protein-ligand binding sites using structural, divergence and human variation data. Additionally, a web server is developed for users to explore this large dataset, named LIGYSIS, as well as analyse their own custom protein-ligand complexes. Finally, \autoref{chap:LBS_COMP} and \autoref{chap:LBS_IMPROV} describes the largest comparative performance assessment of ligand binding site prediction to date including 13 canonical methods and 15 novel variants defined in this work. Beyond ranking the methods by their prediction capability using several relevant metrics, this benchmark provides insight into the strengths and weaknesses of each method and paves the way for improvement in the field of ligand site prediction.




% WHAT IS LEFT?


% Identifying the protein regions where these molecules bind, understanding the mode in which they do so and characterising that interface is therefore key to understanding and modulating protein function. The UniProt knowledgebase (UPKB) catalogues 248 million protein sequences \cite{UNIPROT_2018_UNIPROT, UNIPROT_2023_UNIPROT}. While structure models for most of these proteins are available through resources such as the AlphaFold Database \cite{VARADI_2022_ALPHAFOLDDB, ABRAMSON_2024_ALPHAFOLD3} and other providers \cite{GUEX_2009_SWISSMODEL, BEIENERT_2016_SWISSMODEL, WATERHOUSE_2018_SWISSMODEL}, only a small fraction present residue-level functional annotations in UniProt -- 55 thousand (0.02\% of UPKB) or include biologically relevant ligands co-crystallised in the Protein Data Bank Europe \cite{wwPDB_2019_PDB} -- 29 thousand (0.01\%). The significant expense and time required for experimental validation underscores an urgent need for computational methods to characterise ligand sites  systematically and highlight residues likely to be relevant to protein function.