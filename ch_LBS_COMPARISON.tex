\chapter{Comparative evaluation of methods for the prediction of protein-ligand binding sites}

\section*{Preface}

This chapter describes the largest benchmark of ligand binding site prediction methods to date, comparing thirteen original methods using 10 informative metrics and LIGYSIS as a reference. LIGYSIS is compared to widely used training and test sets and evidence shown of the advantages of using LIGYSIS over these other sets. Finally, top-$N$+2 recall is proposed as a universal benchmark metric for ligand binding site prediction, with a recommendation for open-source sharing of both methods and benchmarks.

\section*{Publications}

Utgés, J.S. and Barton, G.J. Comparative evaluation of methods for the prediction of protein-ligand binding sites. \textit{J Cheminform} \textbf{16}, 126 (2024). \url{https://doi.org/10.1186/s13321-024-00923-z}.

\section*{Author contributions}

J.S.U. and G.J.B. conceived, designed, and developed the research. J.S.U. analysed the data. J.S.U. developed the software. J.S.U. and G.J.B. wrote, reviewed and edited the manuscript. G.J.B. secured funding and supervised.

\section{Introduction}

Identifying where ligands can bind to proteins is of critical importance in understanding and modulating protein function. While X-ray crystallography remains the gold-standard to identify and characterise binding sites \cite{CONGREVE_2003_RO3, REES_2004_FBLD, MURRAY_2009_FBDD, SCHIEBEL_2016_FRAGMENTS, UTGES_2024_FRAGSYS}, over the last three decades, significant effort has been made to develop computational methods that predict binding sites from an apo three-dimensional protein structure \cite{VOLKAMER_2010_TOPOLOGY}.

% Please add the following required packages to your document preamble:
% \usepackage{longtable}
% Note: It may be necessary to compile the document several times to get a multi-page table to line up properly
\begin{longtable}{|c|c|c|c|c|c|c|}
\hline
\textbf{Method}      & \textbf{Source} & \textbf{Review} & \textbf{Install} & \textbf{Docs} & \textbf{Model} & \textbf{Included} \\ \hline
\endfirsthead
%
\multicolumn{7}{c}%
{{\bfseries Table \thetable} (continued)} \\
\hline
\textbf{Method}      & \textbf{Source} & \textbf{Review} & \textbf{Install} & \textbf{Docs} & \textbf{Model} & \textbf{Included} \\ \hline
\endhead
%
\textbf{VN-EGNN}     & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\cmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\cmark}        \\ \hline
\textbf{IF-SitePred} & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\cmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\cmark}        \\ \hline
\textbf{GrASP}       & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\cmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\cmark}        \\ \hline
RefinePocket         & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{?}                & \textbf{\xmark}    & \textbf{\cmark}     & \textbf{\xmark}        \\ \hline
EquiPocket           & \textbf{\cmark}      & \textbf{\xmark}      & \textbf{?}                & \textbf{\xmark}    & \textbf{\cmark}     & \textbf{\xmark}        \\ \hline
GLPocket             & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{?}                & \textbf{\xmark}    & \textbf{\cmark}     & \textbf{\xmark}        \\ \hline
SiteRadar            & \textbf{\xmark}      & \textbf{\cmark}      & \textbf{\xmark}       & \textbf{\xmark}    & \textbf{\xmark}     & \textbf{\xmark}        \\ \hline
NodeCoder            & \textbf{\cmark}      & \textbf{\xmark}      & \textbf{?}                & \textbf{\cmark}    & \textbf{\xmark}     & \textbf{\xmark}        \\ \hline
\textbf{DeepPocket}  & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\cmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\cmark}        \\ \hline
RecurPocket          & \textbf{\cmark}      & \textbf{\xmark}      & \textbf{?}                & \textbf{\xmark}    & \textbf{\cmark}     & \textbf{\xmark}        \\ \hline
PointSite            & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\xmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\xmark}        \\ \hline
DeepSurf             & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\xmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\xmark}        \\ \hline
\textbf{PUResNet}    & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\cmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\cmark}        \\ \hline
Kalasanty            & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\xmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\xmark}        \\ \hline
BiteNet              & \textbf{\xmark}      & \textbf{\cmark}      & \textbf{\xmark}       & \textbf{\cmark}    & \textbf{\xmark}     & \textbf{\xmark}        \\ \hline
GRaSP                & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\cmark}       & \textbf{\xmark}    & \textbf{\cmark}     & \textbf{\xmark}        \\ \hline
\textbf{P2Rank}      & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\cmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\cmark}        \\ \hline
\textbf{PRANK}       & \textbf{\cmark}      & \textbf{\cmark}      & \textbf{\cmark}       & \textbf{\cmark}    & \textbf{\cmark}     & \textbf{\cmark}        \\ \hline
DeepSite             & \textbf{\xmark}      & \textbf{\cmark}      & \textbf{\xmark}       & \textbf{\xmark}    & \textbf{\xmark}     & \textbf{\xmark}        \\ \hline
\caption[Method selection criteria]{\textbf{Method selection criteria.} These are the criteria employed to select machine learning-based methods for this benchmark. Nineteen machine learning-based methods were considered and seven were selected as all requirements were met. Source: whether the method is open source and code is publicly accessible; Review: whether the method has been published after peer-review; Install: whether installation of the method was successful; Docs: whether the method is sufficiently documented to install it and run it on an example input; Model: whether the method provides pre-trained model weights; Included: whether the method was included in this analysis. Check marks(\cmark) indicate meeting the requirement and crosses (\xmark) the opposite. Question marks (\textbf{?}) indicate uncertainty. Installation was not attempted for some methods as they already did not meet other requirements. Methods in bold font are the ones included in this work.}
\label{tab:method_selection}\\
\end{longtable}

Prediction methods exploit a variety of different techniques to suggest binding sites. Geometry-based techniques like fpocket \cite{GUILLOUX_2009_FPOCKET}, Ligsite \cite{HENDLICH_1997_LIGSITE} and Surfnet \cite{LASKOWSKI_1995_SURFNET} identify cavities by analysing the geometry of the molecular surface of a protein and usually rely on the use of a grid, gaps, spheres, or tessellation \cite{GUILLOUX_2009_FPOCKET, LIANG_1998_CAVITIES, HENDLICH_1997_LIGSITE, LASKOWSKI_1995_SURFNET, KLEYWEGT_1994_CAVITIES, LEVITT_1992_POCKET, BRADY_2000_PASS, WEISEL_2007_POCKETPICKER}. Energy-based methods such as PocketFinder \cite{AN_2005_POCKETFINDER} rely on the calculation of interaction energies between the protein and a chemical group or probe to identify cavities \cite{AN_2005_POCKETFINDER, GOODFORD_1982_PREDICTOR, AN_2004_PREDICTOR, LAURIE_2005_QSITEFINDER, GHERSI_2009_SITEHOUND, NGAN_2012_FTSITE}. Conservation-based methods make use of sequence evolutionary conservation information to find patterns in multiple sequence alignments and identify conserved key residues for ligand site identification \cite{ARMON_2001_CONSURF, PUPKO_2002_RATE4SITE, XIE_2012_CONSPRED}. Template-based methods rely on structural information from homologues and the assumption that structurally conserved proteins might bind ligands at a similar location \cite{ZVELEBIL_1987_PREDICTION, WASS_2010_3DLIGANDSITE, ROY_2012_COFACTOR, YANG_2013_COFACTOR, LEE_2013_PREDICTION, BRYLINSKI_2013_EFINDSITE}. Combined approaches or meta-predictors combine multiple methods, or the use of multiple types of data, to infer ligand binding sites, e.g., geometric features with sequence conservation \cite{GUTTERIDGE_2003_LBSP, HUANG_2006_BU48, GLASER_2006_PREDICTION, HALGREN_2009_PREDICITON, CAPRA_2009_CONCAVITY, HUANG_2009_METAPOCKET, BRAY_2009_SITESIDENTIFY, BRYLINSKI_2009_FINDSITE}. Finally, machine learning methods utilise a wide range of machine learning techniques including random forest, as well as deep, graph, residual, or convolutional neural networks \cite{KRIVAK_2015_PRANK, KRIVAK_2015_P2RANK, JIMENEZ_2017_DEEPSITE, KRIVAK_2018_P2RANK, SANTANA_2020_GRaSP, KOZLOVSKII_2020_BITENET, STEPNIEWSKA_2020_KALASANTY, KANDEL_2021_PURESNET, MYOLNAS_2021_DEEPSURF, YAN_2022_POINTSITE, LI_2022_RECURPOCKET, AGGARWAL_2022_DEEPPOCKET, ABDOLLAHI_2023_NODECODER, EVTEEV_2023_SITERADAR, LI_2023_GLPOCKET, ZHANG_2024_EQUIPOCKET, LIU_2023_REFINEPOCKET,  SMITH_2024_GrASP, CARBERY_2024_IFSP, SESTAK_2024_VNEGNN, KANDEL_2024_PURESNET}. Machine learning methods comprise the bulk of the methods reviewed in this analysis and are exemplified by PRANK \cite{KRIVAK_2015_PRANK}, P2Rank \cite{KRIVAK_2015_P2RANK, KRIVAK_2018_P2RANK}, DeepPocket \cite{AGGARWAL_2022_DEEPPOCKET}, PUResNet \cite{KANDEL_2021_PURESNET, KANDEL_2024_PURESNET}, GrASP \cite{SMITH_2024_GrASP}, IF-SitePred \cite{CARBERY_2024_IFSP} and VN-EGNN \cite{SESTAK_2024_VNEGNN}. Open source, peer-reviewed and easy-to-install methods were prioritised \autoref{tab:method_selection}. This set of method represents the most complete and relevant set of ligand binding site prediction tools benchmarked to date and is representative of the state-of-the-art within the field.

\autoref{tab:methods_details_1} and \autoref{tab:methods_details_2} summarise the methods evaluated in this work, which were executed with their standard settings. VN-EGNN \cite{SESTAK_2024_VNEGNN} combines virtual nodes with equivariant graph neural networks. Virtual nodes, represented by ESM-2 embeddings \cite{RIVES_2021_EMBEDDINGS} are passed through a series of message-passing layers until they reach their final coordinates, which represent the centroid of predicted pockets. Pocket residues are not reported. IF-SitePred \cite{CARBERY_2024_IFSP} represents protein residues with ESM-IF1 embeddings \cite{HSU_2022_EMBEDDINGS} and employs 40 different light gradient boosting machine (LGBM) models \cite{KE_2017_LIGHTGBM} to classify residues as ligand-binding if all forty models return a $p >$ 0.5. It later utilises PyMOL \cite{SCHRODINGER_2015_PYMOL} to place a series of cloud points which are clustered using DBSCAN \cite{ESTER_1996_DBSCAN}  and a threshold of 1.7 \AA{}. Pocket centroids are obtained by averaging the clustered points’ coordinates, scored and ranked based on the number of cloud points. Like VN-EGNN, no pocket residues are defined. GrASP \cite{SMITH_2024_GrASP} employs graph attention networks to perform semantic segmentation on all surface protein atoms, represented by 17 atom, residue and bond-level features, scoring which are likely part of a binding site. Atoms with a score $>$ 0.3 are clustered into binding sites using average linkage and a threshold of 15 \AA{}. Pocket scores are calculated as the sum of squares of binding site atom scores. PUResNet \cite{KANDEL_2021_PURESNET} combines deep residual and convolutional neural networks to predict ligand binding sites using an 18-element vector of atom-level features and one-hot encoding to represent grid voxels. Voxels with a score $>$ 0.34 are clustered into binding sites using DBSCAN and a threshold of 5.5 \AA{} \cite{KANDEL_2024_PURESNET}. Pockets are represented by their residues, but neither pocket centroid, nor score or ranking are reported. Similarly to PUResNet, DeepPocket \cite{AGGARWAL_2022_DEEPPOCKET} exploits convolutional neural networks on grid voxels represented by 14 atom-level features to re-score (DeepPocket\textsubscript{RESC}) and additionally extract new pocket shapes (DeepPocket\textsubscript{SEG}) from fpocket candidates. P2Rank \cite{KRIVAK_2018_P2RANK} relies on solvent accessible surface (SAS) points placed over the protein surface, represented by 35 atom and residue-level features, and a random forest classifier to score them based on their likelihood of binding a ligand. SAS points with a score $>$ 0.35 are clustered into sites using single linkage and a threshold of 3 \AA{}. P2Rank\textsubscript{CONS} \cite{JENDELE_2019_PRANKWEB} works in the same manner but considers an extra feature: amino acid conservation as measured by Jensen-Shannon divergence \cite{CAPRA_2007_JSD}. Both report residue and pocket level scores, as well as pocket centroids and rank. PocketFinder \cite{AN_2005_POCKETFINDER} uses the Lennard-Jones \cite{JONES_1924_POTENTIAL} transformation on a 1 \AA{} grid surrounding the protein surface to predict protein cavities. PocketFinder does not report pocket centroid, score or rank. Finally, geometry-based methods: fpocket \cite{GUILLOUX_2009_FPOCKET}, Ligsite \cite{HENDLICH_1997_LIGSITE} and Surfnet \cite{LASKOWSKI_1995_SURFNET} rely on the geometry of the molecular surface to find cavities. fpocket is the only one of these three methods that reports pocket centroid, score, rank and residues. Additionally, fpoket reports multiple pocket features including surface aream volume, hydrophobicity, charge or druggability. 

In this chapter, thirteen ligand binding site prediction tools are compared against the LIGYSIS reference dataset, introduced in \autoref{chap:LIGYSIS_WEB}. LIGYSIS identifies human protein-ligand binding sites for biologically relevant ligands, defined by BioLiP \cite{YANG_2013_BIOLIP}, from protein structures determined by X-ray crystallography. Thirteen methods are compared to each other and to the LIGYSIS reference dataset according to a range of metrics including the number of ligand sites, their size, shape, proximity and overlap. The work described in this chapter identifies the strengths and weaknesses of prediction assessment metrics and leads to guidance for developing ligand binding site prediction tools or using these methods to understand protein function and in drug development. This work represents the first independent ligand site prediction benchmark for over a decade, since Schmidtke \textit{et al.} \cite{SCHMIDTKE_2010_BENCHMARK} or Chen \textit{et al.} \cite{CHEN_2011_ASSESSMENT} and the largest to date in terms of dataset size (2775), methods compared (13) and metrics employed ($>$10).

\begin{landscape}
\begin{longtable}{|M{25mm}|M{29mm}|M{27mm}|M{22mm}|M{19mm}|M{19mm}|M{15mm}|M{15mm}|M{15mm}|M{16mm}|M{15mm}|M{23mm}|M{15mm}|}
\hline
\textbf{Method} & \textbf{Approach}  & \textbf{Features} & \textbf{\# Features}   & \textbf{P centroid}    & \textbf{P residues} & \textbf{P score} & \textbf{P rank} & \textbf{R score} \\ \hline
\endfirsthead
%\multicolumn{9}{c}%
%{{\bfseries Table \thetable} (continued)} \\
%\hline
%\textbf{Method} & \textbf{Approach}  & \textbf{Features} & \textbf{\# Features}   & \textbf{P centroid}    & \textbf{P residues} & \textbf{P score} & \textbf{P rank} & \textbf{R score}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     
%
\endhead
%
VN-EGNN       & EGNN + VN                     & ESM-2 embeddings        & 1280       & \textbf{\cmark}         & \textbf{\xmark}         & \textbf{\cmark}      & \textbf{\cmark}        & \textbf{\xmark}      \\ \hline
IF-SitePred   & LGBM                      & ESM-IF1 embeddings      & 512         & \textbf{\cmark}        & \textbf{\xmark}         & \textbf{\cmark}      & \textbf{\cmark}        & \textbf{\xmark}      \\ \hline
GrASP         & GAT - GNN                     & Atom + residue + bond    & 17          & \textbf{\cmark}         & \textbf{\cmark}         & \textbf{\cmark}      & \textbf{\cmark}        & \textbf{\cmark}      \\ \hline
PUResNet      & DRN + 3D-CNN                  & Atom + one-hot encoding & 18          & \textbf{\xmark}         & \textbf{\cmark}         & \textbf{\xmark}      & \textbf{\xmark}        & \textbf{\xmark}      \\ \hline
DeepPocket    & fpocket + 3D-CNN                        & Atom                    & 14          & \textbf{\cmark}         & \textbf{\cmark}         & \textbf{\cmark}      & \textbf{\cmark}        & \textbf{\xmark}      \\ \hline
P2Rank\textsubscript{CONS}    & Random Forest                 & Atom + residue        & 36          & \textbf{\cmark}         & \textbf{\cmark}         & \textbf{\cmark}      & \textbf{\cmark}        & \textbf{\cmark}      \\ \hline
P2Rank        & Random Forest                 & Atom + residue        & 35          & \textbf{\cmark}         & \textbf{\cmark}         & \textbf{\cmark}      & \textbf{\cmark}        & \textbf{\cmark}      \\ \hline
fpocket\textsubscript{PRANK}       & fpocket + Random Forest & Atom + residue                       & 34           & \textbf{\xmark}         & \textbf{\cmark}         & \textbf{\cmark}      & \textbf{\cmark}        & \textbf{\xmark}      \\ \hline
fpocket       & $\alpha$-spheres & \textbf{--}                       & \textbf{--}           & \textbf{\xmark}         & \textbf{\cmark}         & \textbf{\cmark}      & \textbf{\cmark}        & \textbf{\xmark}      \\ \hline
PocketFinder\textsuperscript{+} & LJ potential                  & \textbf{--}                       & \textbf{--}           & \textbf{\xmark}         & \textbf{\xmark}         & \textbf{\xmark}      & \textbf{\xmark}        & \textbf{\cmark}      \\ \hline
Ligsite\textsuperscript{+}      & Cubic grid                    & \textbf{--}                       & \textbf{--}           & \textbf{\xmark}         & \textbf{\xmark}         & \textbf{\xmark}      & \textbf{\xmark}        & \textbf{\cmark}      \\ \hline
Surfnet\textsuperscript{+}      & Gap regions                   & \textbf{--}                       & \textbf{--}           & \textbf{\xmark}         & \textbf{\xmark}         & \textbf{\xmark}      & \textbf{\xmark}        & \textbf{\cmark}      \\ \hline
%\newpage
\caption[Ligand binding site prediction methods summary (I)]{\textbf{Ligand binding site prediction methods summary (I).} All these methods were used with their default settings. Check marks (\cmark) indicate that a method provides a given output and crosses (\xmark) the contrary. Dashes (\textbf{--}) indicate a field is not applicable for a given method, e.g., features for non-machine learning-based methods. Approach: the techniques applied by the method; Features/\# Features: the features and their number if the method is machine learning-based; P centroid/P residues/P score/P rank/R score: whether the method reports the pocket centroid, pocket residues, pocket score, pocket ranking and residue \textit{ligandability} score. For example, P2Rank uses a random forest classifier on SAS points represented by 35 atom and residue features. EGNN + VN: equivariant graph neural network + virtual nodes; LGBM: Light gradient boosting machine; GAT: graph attention network; GNN: graph neural network; DRN: deep residual network; 3D-CNN: three-dimensional convolutional neural network; LJ potential: Lennard-Jones potential.}
\label{tab:methods_details_1}\\
\end{longtable}
\end{landscape}

\begin{landscape}
\begin{longtable}{|M{35mm}|M{45mm}|M{35mm}|M{35mm}|M{35mm}|}
\hline
\textbf{Method} & \textbf{R score threshold}  & \textbf{Cluster} & \textbf{Algorithm}   & \textbf{Threshold} (\AA{})\\ \hline
\endfirsthead
%\multicolumn{9}{c}%
%{{\bfseries Table \thetable} (continued)} \\
%\hline
%\textbf{Method} & \textbf{Approach}  & \textbf{Features} & \textbf{\# Features}   & \textbf{P centroid}    & \textbf{P residues} & \textbf{P score} & \textbf{P rank} & \textbf{R score}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     
%
\endhead
%
VN-EGNN       & \textbf{--}                 & \textbf{--}            & \textbf{--}         & \textbf{--}         \\ \hline
IF-SitePred   & 0.50 (\textit{all} 40)      & Cloud points & DBSCAN    & 1.7       \\ \hline
GrASP         & 0.30               & Atoms        & Average   & 15        \\ \hline
PUResNet      & 0.34              & Atoms        & DBSCAN    & 5.5       \\ \hline
DeepPocket    & \textbf{--}                 & \textbf{--}            & \textbf{--}         & \textbf{--}         \\ \hline
P2Rank\textsubscript{CONS}    & 0.35              & SAS points   & Single    & 3         \\ \hline
P2Rank        & 0.35              & SAS points   & Single    & 3         \\ \hline
fpocket       & \textbf{--}                 & $\alpha$-spheres   & Multiple  & 1.7, 4.5, 2.5         \\ \hline
fpocket\textsubscript{PRANK}       & \textbf{--}                 & \textbf{--}   & \textbf{--}  & \textbf{--}         \\ \hline
PocketFinder\textsuperscript{+} & \textbf{--}                 & Grid points            & \textbf{?}         & \textit{search}         \\ \hline
Ligsite\textsuperscript{+}      & \textbf{--}                 & Grid points            & \textbf{?}         & \textit{search} \\ \hline
Surfnet\textsuperscript{+}      & \textbf{--}                 & Grid points            & \textbf{?}         & \textit{search}      \\ \hline
\caption[Ligand binding site prediction methods summary (II)]{\textbf{Ligand binding site prediction methods summary (II).} All these methods were used with their default settings. Information about the clustering strategies employed by the methods. R score threshold: whether the method uses a residue ligandability threshold; Cluster: the instances they cluster to define the distinct pockets; Algorithm: the clustering algorithm used; Threshold: the distance threshold employed (\AA{}). For example, GrASP utilises average linkage clustering on atoms with predicted ligandability score $>$ 0.30 and a threshold of 15 \AA{}. A dash (\textbf{--}) indicates that the category is not applicable, i.e., VN-EGNN does not employ clustering in their prediction of ligand binding sites. Question marks (\textbf{?}) indicate variables for which values were not be found. ``\textit{search}'' represents an iterative process to find optimal clustering thresholds.}
\label{tab:methods_details_2}\\
\end{longtable}
\end{landscape}

\section{Methods}

\subsection{Comparison of datasets}

Training and test datasets were downloaded for all machine learning-based methods reviewed in this chapter. Datasets were compared to the LIGYSIS reference set, in terms of number of sites per protein, ligand-interacting chains, chain length, site size (number of amino acids), ligand composition, size and diversity. Ligand diversity was quantified by Shannon's Entropy \cite{SHANNON_1948_ENTROPY} (\autoref{eq:entropy_shannon}) where $p_i$ represents the proportion of each ligand $i$ of the $R$ ligands observed in a dataset. Ligand data was extracted from the Chemical Component Dictionary (CCD) \cite{WESTBROOK_2015_CCD}. An overlap (\%) was calculated for each dataset as the proportion of LIGYSIS binding sites that were covered by at least one ligand in a test dataset. A simplistic approach was adopted by calculating the intersection of ligand codes between LIGYSIS and each dataset. Ligand codes were defined as a string of PDB ID + ``\_'' + ligand ID, e.g., ``6GXT\_GTP'' corresponds to the guanosine-5’-triphosphate (GTP) of the PDB entry with ID: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/6gx7}{6GX7} \cite{CAMPANACCI_2019_TUBULIN}.

\begin{equation}
H' = - \sum_{i=1}^{R} p_i \ln(p_i)
\label{eq:entropy_shannon}
\end{equation}
\myequations{Shannon's Entropy}

\subsection{Training datasets}

VN-EGNN is trained on a subset \cite{KANDEL_2021_PURESNET} of the sc-PDB (v2017) \cite{PAUL_2004_SCPDB, KELLENBERGER_2006_SCPDB, MESLAMANI_2011_SCPDB, DESAPHY_2015_SCPDB} (sc-PDB\textsubscript{SUB}). sc-PDB is a comprehensive database of pharmacological ligand-protein complexes. The database is composed of proteins in complex with buried, biologically relevant synthetic or natural ligands deposited in the PDB. sc-PDB contains unique non-repeating protein-ligand pairs, meaning that only one ligand is considered per PDB entry. Smith \textit{et al.} \cite{SMITH_2024_GrASP} enriched this dataset with 9000 extra ligands resulting in a version of sc-PDB referred to here as sc-PDB\textsubscript{RICH}, which GrASP trained on. This dataset is not publicly accessible and therefore not considered in this analysis. DeepPocket used the full sc-PDB set to train on, sc-PDB\textsubscript{FULL}. IF-SitePred used a sequence identity-filtered version of the non-redundant subset of the binding mother of all databases (MOAD) \cite{HU_2005_BMOAD, BENSON_2008_BMOAD, AHMED_2015_BMOAD, SMITH_2019_BMOAD}, which considers only protein family leaders. The binding MOAD, here referred to as bMOAD\textsubscript{SUB}, is a large collection of crystal structures with clearly identifies biologically relevant ligands with binding data extracted from the literature. Finally, PRANK and P2Rank used the CHEN11 dataset to train, which aimed to cover all SCOP \cite{HUBBARD_1997_SCOP, HUBBARD_1998_SCOP, LOCONTE_2000_SCOP} families of ligand binding proteins in a non-redundant manner \cite{CHEN_2011_ASSESSMENT}. P2Rank utilised the JOINED dataset for validation. CHEN11 not only considers the ligands in each structure but is enriched with ligands binding to homologous structures. JOINED is a combined dataset formed by other smaller datasets: ASTEX \cite{HARTSHORN_2007_ASTEX}, UB48 \cite{HUANG_2006_BU48}, DT198 \cite{ZHANG_2011_METAPOCKET} and MP210 \cite{HUANG_2009_METAPOCKET}, which represent diverse collections of protein-ligand complexes, including bound/unbound states, drug-target complexes and other ligand site predictor benchmark sets.

\subsection{Test datasets}

The majority of ligand binding site predictors published since 2018 have been using two datasets that were first presented by Krivák \textit{et al.} \cite{KRIVAK_2018_P2RANK}: COACH420 and HOLO4K, or subsets of them. COACH420 is comprised by a set of 420 single-chain structures binding a mix of drug-like molecules and naturally occurring ligands which is disjunct with the CHEN11 and JOINED datasets. COACH420 is a modified version of the original COACH test set \cite{ROY_2012_COFACTOR, YANG_2013_COFACTOR}. HOLO4K is a larger set, $N \approx$ 4000, based on the list by Schmidtke \textit{et al.} \cite{SCHMIDTKE_2010_BENCHMARK}, which includes a mix of single- and multi-chain complexes, also disjunct with P2Rank training (CHEN11) and validation (JOINED) datasets. PRANK employed the small datasets comprising the JOINED set for testing. VN-EGNN, DeepPocket and GrASP use the Mlig and Mlig+ subsets of the COACH and HOLO4K datasets, which include strictly biologically relevant ligands as defined by the binding MOAD. IF-SitePred tested on the HOLO4K-AlphaFold2 Paired (HAP) and HAP-small sets. HAP is a subset of the HOLO4K dataset which presents high quality models in the AlphaFold database \cite{VARADI_2022_ALPHAFOLDDB}. HAP-small is a smaller subset of HAP that only contains proteins with sequence identity lower than 25\% to proteins in the P2Rank training set. VN-EGNN uses the refined version of PDBbind (v2020), referred here as PDBbind\textsubscript{REF}, \cite{WANG_2004_PDBBIND, WANG_2005_PDBBIND, CHENG_2009_PDBBIND, LI_2014_PDBBIND, LIU_2015_PDBBIND, LIU_2017_PDBBIND} as a third test set. Like binding MOAD, the PDBbind database provides a comprehensive collection of experimentally measured binding affinity data for macromolecular complexes. Specifically, the refined set includes those protein-ligand complexes for which binding data was obtained with the literature and met certain experimental quality thresholds. Lastly, SC6K is a dataset presented by Aggarwal \textit{et al.} \cite{AGGARWAL_2022_DEEPPOCKET} containing 6000 protein-ligand pairs from PDB entries submitted from 01/01/2018 – 28/02/2020.

\subsection{Protein chain alignment}

For each protein chain, atomic coordinates were translated to be centred at the origin, $O = (0, 0, 0)$, and rotated using a rotation matrix, $R$. The two principal components of the coordinate space $pc_{1}$ and $pc_{2}$ were obtained using principal component analysis (PCA) \cite{HOTELLING_1933_PCA}. A third component, $pc_{\perp}$, was obtained with the cross-product of the other two, to ensure orthogonality. A rotation matrix $P$ was constructed from these vectors (\autoref{eq:pca_components}). By placing the main component $pc_{1}$ on the second row of $P$, the $Y$ axis was fixed as the major axis, representing the height of the protein chain. The second largest axis is the $X$ axis, representing the width of the protein, and lastly the depth is represented by the smaller magnitude of the $Z$ axis. The final rotation matrix $R$ was obtained by multiplying $P$ by the negative identity matrix $NI$ (\autoref{eq:NI_matrix} and \autoref{eq:R_matrix}). This was done to maintain the left-handedness of the protein chains whilst ensuring a consistent alignment on the major axes.

\begin{equation}
pc_{\perp} = pc_{1} \times pc_{2} \quad \rightarrow \quad P = \begin{bmatrix}
pc_{2} \\
pc_{1} \\
pc_{\perp}
\end{bmatrix}
\label{eq:pca_components}
\end{equation}
\myequations{Principal Components Vector}

\begin{equation}
NI = -1 \cdot I_3 = -1 \cdot \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 
\end{bmatrix} = \begin{bmatrix}
-1 & 0 & 0 \\
0 & -1 & 0 \\
0 & 0 & -1 
\end{bmatrix}
\label{eq:NI_matrix}
\end{equation}
\myequations{Negative Identity Matrix}

\begin{equation}
R = P \cdot NI
\label{eq:R_matrix}
\end{equation}
\myequations{Rotation Matrix}

\subsection{Protein chain characterisation}

For a protein chain with $N$ amino acid residues, the centre of mass, $CM$, was calculated by averaging the coordinates, $r_{i}$, of all atoms (\autoref{eq:centre_of_mass}), and from it, the radius of gyration, $R_{g}$, was derived (\autoref{eq:radius_of_gyration}) \cite{FIXMAN_1962_ROG}. Since the protein chains were already aligned on the axis and centred on $O = (0, 0, 0)$, the dimensions of the protein chain could be obtained as the magnitude of the PCA components or \textit{eigenvectors}, i.e., the \textit{eigenvalues}. The dimensions represent width, height, and depth for the $X$, $Y$ and $Z$ axes, respectively.

\begin{equation}
CM = \frac{1}{n} \sum_{i=1}^{n} r_i \rightarrow CM = O = (0,0,0)
\label{eq:centre_of_mass}
\end{equation}
\myequations{Centre of Mass}

\begin{equation}
R_g = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (r_i - CM)^2} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (r_i - O)^2} \rightarrow R_g = \sqrt{\frac{1}{n} \sum_{i=1}^{n} r_i^2}
\label{eq:radius_of_gyration}
\end{equation}
\myequations{Radius of Gyration}

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG11_PROTEIN_SHAPE_APPROACH_3_SPLIT1.png}
    \caption[Protein chain shape and size classification approach]{\textbf{Protein chain shape and size classification approach.} The volume of the sphere enclosing the protein chain as well as the protein chain volumes were calculated, and their ratio obtained ($V_R$). Globular proteins present more spherical shapes and therefore occupy a higher portion of the sphere volume, resulting in higher volume ratios. Non-globular, elongated or fibrous proteins on the other hand do not and present lower volume ratios. After extensive visual examination, a threshold was established at $V_R$ = 0.08, and so proteins classified in these two groups. Proteins were classified as ``tiny'' if their chain was $\leq$ 100 amino acids. Examples for each class are from left to right: \href{https://www.uniprot.org/uniprotkb/Q9Y5G1/entry}{Q9Y5G1} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/6mer}{6MER} \cite{NICLOLUDIS_2019_CADH}, chain: A; \href{https://www.uniprot.org/uniprotkb/P05412/entry}{P05412} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5t01}{5T01} \cite{HONG_2017_EPSTEINBARR}, chain: A; \href{https://www.uniprot.org/uniprotkb/Q12884/entry}{Q12884} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/6Y0F}{6Y0F} \cite{PDB_6Y0F}, chain: A; \href{https://www.uniprot.org/uniprotkb/Q8NE86/entry}{Q8NE86} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5KUJ}{5KUJ} \cite{LEE_2016_CALCIUM}. chain: A.}
    \label{fig:protein_class_approach}
\end{figure}

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG11_PROTEIN_SHAPE_APPROACH_2_SPLIT2.png}
    \caption[Protein shape class examples]{\textbf{Protein shape class examples.} Four examples of each protein chain group to illustrate the outcome of the approach. Elongated: \href{https://www.uniprot.org/uniprotkb/Q8NEZ3/entry}{Q8NEZ3} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/8FGW}{8FGW} \cite{JIANG_2023_IFTA}, chain: C; \href{https://www.uniprot.org/uniprotkb/P02679/entry}{P02679} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/3GHG}{3GHG} \cite{KOLLMAN_2009_FIBRINOGEN}, chain: C; \href{https://www.uniprot.org/uniprotkb/Q14126/entry}{Q14126} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/7A7D}{7A7D} \cite{SIKORA_DESMOSOME}, chain: A; \href{https://www.uniprot.org/uniprotkb/Q08554/entry}{Q08554} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5IRY}{5IRY} \cite{HARRISON_2016_DESMOCOLLINS}, chain: A. Elongated + tiny: \href{https://www.uniprot.org/uniprotkb/Q9H2S9/entry}{Q9H2S9} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/2MA7}{2MA7} \cite{PDB_2MA7}, chain: A; \href{https://www.uniprot.org/uniprotkb/Q9BV73/entry}{Q9BV73} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/6OQA}{6OQA} \cite{SHIGDEL_2020_SMALLMOL}, chain: H; \href{https://www.uniprot.org/uniprotkb/Q8IYW5/entry}{Q8IYW5} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5YDK}{5YDK} \cite{TAKAHASHI_2018_RNF168}, chain: F; \href{https://www.uniprot.org/uniprotkb/P60880/entry}{P60880} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/3rk2}{3RK2} \cite{KUMMEL_2011_SNARES}, chain: G. Globular: \href{https://www.uniprot.org/uniprotkb/O43451/entry}{O43451} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/3TOP}{3TOP} \cite{REN_2011_MALTASE}, chain: A; \href{https://www.uniprot.org/uniprotkb/P21399/entry}{P21399} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/2B3Y}{2B3Y} \cite{DUPUY_2006_ACONITASE}, chain: A; \href{https://www.uniprot.org/uniprotkb/Q9UI17/entry}{Q9UI17} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5L46}{5L46} \cite{AUGUSTIN_2016_DEHYDRO}, chain: B; \href{https://www.uniprot.org/uniprotkb/P27487/entry}{P27487} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/3VJM}{3VJM} \cite{YOSHIDA_2012_DPP4}, chain: A. Globular + tiny: \href{https://www.uniprot.org/uniprotkb/Q9UN19/entry}{Q9UN19} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1FAO}{1FAO} \cite{FERGUSON_2000_PLECKSTRIN}, chain: A; \href{https://www.uniprot.org/uniprotkb/Q12923/entry}{Q12923} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1D5G}{1D5G} \cite{KOZLOV_2002_PDZ}, chain: A; \href{https://www.uniprot.org/uniprotkb/P42566/entry}{P42566} -- PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1C07}{1C07} \cite{ENMON_2000_EPS15}, chain: A; \href{https://www.uniprot.org/uniprotkb/P42566/entry}{P42566} PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1EH2}{1EH2} \cite{BEER_1998_EPS15}, chain: A.}
    \label{fig:protein_class_examples}
\end{figure}

Protein chain volumes were calculated using ProteinVolume \cite{CHEN_2015_PROTEINVOLUME}. A sphere enclosing the protein and centred on the protein centre of mass was obtained. The radius of this sphere was the maximum Euclidean distance between the protein atoms and the CM (\autoref{eq:radius_protein}). The volume of the sphere is calculated using \autoref{eq:volume_sphere}. Proteins were classified into four different groups based on their shape and size. Protein chains with $\leq$ 100 amino acids were classified as ``tiny''. Regarding the shape, protein chains were classified into ``elongated'' if their protein to sphere volume ratio $\leq$ 0.08 ($V_R$) (\autoref{eq:volume_ratio}), i.e., the protein volume contains no more than 8\% of the sphere volume. This threshold was derived empirically by the visual inspection of all 3448 protein chains on the LIGYSIS set. Otherwise, proteins were considered globular (\autoref{fig:protein_class_approach}). In this manner, protein chains were classified into \textit{globular} ($N$ = 2104; 61\%), \textit{elongated} ($N$ = 670; 19\%), \textit{elongated tiny} ($N$= 341; 10\%) and \textit{globular tiny} ($N$ = 333; 10\%).

\begin{equation}
R = \max \| r_i - CM \|
\label{eq:radius_protein}
\end{equation}
\myequations{Protein Radius}

\begin{equation}
V_{S} = \frac{4}{3} \pi R^3
\label{eq:volume_sphere}
\end{equation}
\myequations{Sphere Volume}

\begin{equation}
V_R = \frac{V_{P}}{V_{S}}
\label{eq:volume_ratio}
\end{equation}
\myequations{Volume Ratio}

\FloatBarrier

\subsection{Ligand binding site prediction}

For each segment in the LIGYSIS dataset, the representative chain as defined in the PDBe-KB was selected. Structures were cleaned using the \textit{clean\_pdb.py} script \cite{JUBB_2019_PDBTOOLS}. Eleven different ligand binding site prediction tools were used to predict on the 3448 representative chains: VN-EGNN \cite{SESTAK_2024_VNEGNN}, IF-SitePred \cite{CARBERY_2024_IFSP}, GrASP \cite{SMITH_2024_GrASP}, PUResNet \cite{KANDEL_2021_PURESNET, KANDEL_2024_PURESNET}, DeepPocket \cite{AGGARWAL_2022_DEEPPOCKET}, P2Rank \cite{KRIVAK_2015_P2RANK, KRIVAK_2018_P2RANK}, PRANK \cite{KRIVAK_2015_PRANK}, fpocket \cite{GUILLOUX_2009_FPOCKET, SCHMIDTKE_2010_FPOCKET2}, PocketFinder\textsuperscript{+} \cite{AN_2005_POCKETFINDER}, Ligsite\textsuperscript{+} \cite{HENDLICH_1997_LIGSITE}, and Surfnet\textsuperscript{+} \cite{LASKOWSKI_1995_SURFNET}. Conservation scores for P2Rank were obtained from PrankWeb: \url{https://prankweb.cz/} and used for further prediction. This variant of P2Rank employing amino acid conservation is referred to as P2Rank\textsubscript{CONS} \cite{JENDELE_2019_PRANKWEB, JAKUBEC_2022_PRANKWEB}. When running DeepPocket, the $-r$ threshold was removed and so all fpocket candidates were passed to the CNN-based segmentation module for pocket shape estimation. fpocket predictions re-scored by DeepPocket will be referred as DeepPocket\textsubscript{RESC}, whereas pockets extracted by the segmentation module of DeepPocket will be referred as DeepPocket\textsubscript{SEG}. fpocket predictions were also re-scored with PRANK \cite{KRIVAK_2015_PRANK} (fpocket\textsubscript{PRANK}), as introduced in previous studies \cite{KRIVAK_2015_PRANK, KRIVAK_2015_P2RANK, KRIVAK_2018_P2RANK, COMAJUNCOSA_2024_POCKETS}. Re-implementations of Capra \textit{et al.} \cite{CAPRA_2009_CONCAVITY} were used for PocketFinder, Ligsite and Surfnet, indicated by the ``+'' superscript. VN-EGNN, IF-SitePred, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+} do not provide a list of residues for each pocket, but a list of centroids and their scores for the first two, and a list of grid points for each predicted pocket for the last three. For VN-EGNN, residues within 6 \AA{} of the virtual nodes were considered pocket residues. For 429 predicted pockets ($\approx$3\%) no residues were found within this threshold. For IF-SitePred, residues within 6 \AA{} of the clustered cloud points that resulted on a predicted pocket centroid were considered as pocket residues. Pocket residues were obtained in a similar manner for PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+}, by taking those residues within 6 \AA{} of the pocket grid points. In total, thirteen methods are considered in this analysis: VN-EGNN, IF-SitePred, GrASP, PUResNet, DeepPocket\textsubscript{RESC}, DeepPocket\textsubscript{SEG}, P2Rank\textsubscript{CONS}, P2Rank, fpocket\textsubscript{PRANK}, fpocket, PocketFin-der\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+}.

Seven of the considered methods provide residue \textit{ligandability} scores. P2Rank and P2Rank\textsubscript{CONS} report calibrated probabilities of residues being ligand-binding. Similarly, GrASP predicts the likelihood for any given heavy atom to be part of a binding site. A residue-level score was obtained for GrASP predictions by taking the maximum score of the residue atoms. For IF-SitePred, a residue ligandability score $LS$ was computed by averaging the 40 independently predicted probabilities of a residue being ligand-binding (\autoref{eq:IFSP_score}). Though calculated in a different way, these three scores range 0-1, represent the likelihood of a residue binding a ligand and can therefore be compared. PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+}, and Surfnet\textsuperscript{+} also provide residue scores which maximum value can be $>$ 1.

\begin{equation}
LS = \frac{1}{40} \sum_{i=1}^{40} p_i
\label{eq:IFSP_score}
\end{equation}
\myequations{IF-SitePred ligandability score}

VN-EGNN, PUResNet, DeepPocket\textsubscript{RESC}, DeepPocket\textsubscript{SEG}, fpocket\textsubscript{PRANK} and fpocket do not report residue-level scores. However, binary labels represent whether a residue is part of a pocket (1) or not (0), in the same manner as all other methods.

Throughout this chapter, the terms ``site'' and ``pocket'' are used indistinctly. Methods are sorted in chronological order across all figures, tables and legends.

\subsection{Binding site characterisation}

Radius of gyration, $R_{g}$, was calculated for pockets as it was done for whole protein chains (\autoref{eq:radius_of_gyration}). Distance between pockets was calculated as the Euclidean distance between their centroids and overlap between pocket residues with the Jaccard Index (JI), or intersection over union (IOU) (\autoref{eq:jaccard_index}) \cite{JACCARD_1901_INDEX, JACCARD_1912_INDEX}. POVME 2.0 was employed for pocket volume calculation \cite{DURRANT_2011_POVME, DURRANT_2014_POVME2, WAGNER_2017_POVME3}. A single inclusion region was used for each pocket. This region was defined by the smallest rectangular prism containing all pocket atoms. The prism was centred on the pocket centroid and its dimensions were determined by the distance between the two farthest atomic coordinates on each axis. No exclusion regions were used. Points outside the convex hull were deleted. A contiguous-points region was defined as a 5 \AA{}-radius sphere on the pocket centroid (\autoref{fig:protein_volume_approach}).

\begin{equation}
JI(A, B) = \frac{|A \cap B|}{|A \cup B|}
\label{eq:jaccard_index}
\end{equation}
\myequations{Jaccard Index}

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG12_POCKET_VOLUME_APPROACH.png}
    \caption[Pocket volume calculation algorithm]{\textbf{Pocket volume calculation algorithm.} \textbf{(A)} PUResNet predicted pocket for PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/4PX2}{4PX2} \cite{PDB_4PX2}. Pocket residues are coloured in blue and have their side chains displayed; \textbf{(B)} An inclusion region is determined using the coordinates of the pocket residue atoms; \textbf{(C)} POVME 2.0 calculates the shape of the pocket defined by the residues and contained within the inclusion region; \textbf{(D)} The pocket shape is defined by a series of unit-volume (1 \AA{}\textsuperscript{3}) spheres. The volume of the pocket is calculated as the addition of the sphere volumes or the number of spheres within the pocket. Structure visualisation with PyMOL v2.5.2 \cite{SCHRODINGER_2015_PYMOL}.}
    \label{fig:protein_volume_approach}
\end{figure}

\subsubsection{Determination of DCC threshold}

Most methods employ distance to closest ligand atom  (DCA) and a threshold of 4 \AA{} to consider a prediction as correct. Because of the way the LIGYSIS dataset has been curated, it is easier to use DCC, since binding sites result of the clustering of multiple ligands, and not just a single ligand binding a protein. Despite DCC and DCA being different metrics, the same threshold of 4 \AA{} is used for both when benchmarking methods \cite{AGGARWAL_2022_DEEPPOCKET, SESTAK_2024_VNEGNN, KANDEL_2021_PURESNET}. \autorefpanel{fig:irel_vs_dcc}{A} shows the relation between DCC, and pocket residue overlap for the best pocket predictions, i.e., minimum Euclidean distance between predicted and observed pocket centroid, for each observed pocket for each method. Across all methods, there are more than 15,000 predicted pockets with a DCC $>$ 4 \AA{} and a residue overlap $\geq$ 0.5. Setting the DCC threshold at 4 \AA{} would result in the wrong labelling of these predictions as ``false positives''. For this reason, a more meaningful DCC threshold was empirically established through the thorough visual inspection of predicted-observed pocket pairs. \autorefpanel{fig:irel_vs_dcc}{B} suggests this threshold might be somewhere in between 10-15 \AA{}, where the proportion of pockets with $I_{rel} \geq$ 0.5 decreases until reaching 0.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG10_IREL_vs_DCC.png}
    \caption[$I_{rel}$ \textit{vs} DCC]{\textbf{$I_{rel}$ \textit{vs} DCC.} \textbf{(A)} Hexagonal binned plot of $I_{rel}$ (Y) \textit{vs} DCC (X). Data points are grouped into hexagonal bins which are coloured by the number of data points within each bin using the \textit{viridis} colour palette. Colour bar axis is in log\textsubscript{10} scale. Black dashed lines indicate the literature consensus DCC = 4 \AA{} threshold and an arbitrary $I_{rel}$ threshold of 0.5, i.e., coverage of half of the observed ligand-binding residues by the predicted pocket.  Red lines delimit the likely location of a potentially more informative DCC thresholds; \textbf{(B)} Cumulative proportion of predicted pockets with $I_{rel} \geq$ 0.5 for each DCC 1 \AA{} interval. The commonly used threshold of DCC = 4 \AA{} would label $>$15,000 predictions with $I_{rel} \geq$ 0.5 as false. Error bars indicate 95\% CI of the proportion.}
    \label{fig:irel_vs_dcc}
\end{figure}

A hard threshold was set at D = 20 \AA{} and a decision made so that based purely on distance, pockets with DCC $>$ 20 would not be considered as correct predictions. For each DCC interval of 1 \AA{}, the pocket with the highest and lowest $I_{rel}$ were inspected (\autoref{fig:DCC_determination}). This initial visual inspection supported the hypothesis that a more meaningful DCC threshold is between 10-14 \AA{}. For the next step, only predicted-observed pocket pairs with minimal overlap ($I_{rel} <$ 0.25) were considered. Starting at DCC = 10 \AA{}, and using unit (1 \AA{}) intervals, the 100 farthest pockets were inspected for each interval, and the proportion of correct predictions was calculated as the number of pockets labelled as ``correct'' upon visual inspection divided by 100, i.e., \%. For D = 10 \AA{}, 94\% of pockets were correct (\autoref{fig:DCC_10_examples}), 86\% for D = 11 \AA{} (\autoref{fig:DCC_11_examples}), 85\% for D = 12 \AA{} (\autoref{fig:DCC_12_examples}) and 66\% for D = 13 \AA{}. Due to the considerable drop of correct pockets at D = 13 \AA{}, the final distance threshold was set at D = 12\AA{}. Accordingly, predictions were considered as true positives if DCC $\leq$ 12 \AA{} (\autoref{eq:DCC_threshold}).

\begin{equation}
\textit{True Positive} \iff (\text{DCC} \leq 12\text{\AA{}})
\label{eq:DCC_threshold}
\end{equation}
\myequations{Empirically determined DCC threshold}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG11_DETERMINING_DCC_THRESHOLD.png}
    
    \caption[Determination of DCC threshold]{\textbf{Determination of DCC threshold.} Highest and lowest-residue overlap predictions for each 2 \AA{} DCC unit interval. Observed LIGYSIS sites are coloured in green, predicted pockets in other colours. $D$ represents DCC and $I_{rel}$ the relative intersection between predicted and observed pocket residues, i.e., proportion of observed site residues covered by predicted pocket residues. ``YES'' or ``NO'' labels indicate whether a prediction was considered correct upon visual inspection. ``?'' at DCC = 12 \AA{} illustrates}
    \label{fig:DCC_determination}
\end{figure}

\begin{figure}[ht]
\ContinuedFloat
\caption*{(continued) the inflection point between 10-12 \AA{}, where it is no longer clear whether predicted pockets within this DCC interval and $I_{rel} \approx$ 0 agree with the observed pockets. To facilitate the visualisation of the observed pocket, this one is coloured after the predicted one. Otherwise, for cases where $I_{rel}$ = 1 only the predicted pocket would be shown. Despite 1 \AA{} intervals were inspected, only representatives of 2 \AA{} intervals are shown here for simplicity.}
\end{figure}
\FloatBarrier

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG12_EXAMPLES_DCC_10.png}
    \caption[Predicted-observed pocket pairs at DCC = 10 \AA{} and $I_{rel} <$ 0.25]{\textbf{Predicted-observed pocket pairs at DCC = 10 \AA{} and $I_{rel} <$ 0.25.} Out of the 100 examples visually inspected, 94 were considered as correct predictions on the bases that the predicted and observed pockets are adjacent, i.e., their surface area is in contact, and it is therefore easy to imagine a ligand that would bind to this region. LIGYSIS observed sites are coloured in green, and predicted pockets in other colours.}
    \label{fig:DCC_10_examples}
\end{figure}
\FloatBarrier

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG13_EXAMPLES_DCC_11.png}
    \caption[Predicted-observed pocket pairs at DCC = 11 \AA{} and $I_{rel} <$ 0.25]{\textbf{Predicted-observed pocket pairs at DCC = 11 \AA{} and $I_{rel} <$ 0.25.} Out of the 100 examples visually inspected, 86 were considered as correct predictions. LIGYSIS observed sites are coloured in green, and predicted pockets in other colours.}
    \label{fig:DCC_11_examples}
\end{figure}
\FloatBarrier

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG14_EXAMPLES_DCC_12_NEW.png}
    \caption[Predicted-observed pocket pairs at DCC = 12 \AA{} and $I_{rel} <$ 0.25]{\textbf{Predicted-observed pocket pairs at DCC = 12 \AA{} and $I_{rel} <$ 0.25.} Out of the 100 examples visually inspected, 85 were considered as correct predictions. LIGYSIS observed sites are coloured in green, and predicted pockets in other colours.}
    \label{fig:DCC_12_examples}
\end{figure}
\FloatBarrier

\subsection{Prediction evaluation}

LIGYSIS binding sites consist of sets of UniProt residue numbers to which ligands bind across the multiple structures of a protein. The thirteen ligand binding site predictors benchmarked in this work predict only on the representative chains for each protein. These representative structures are defined in the PDBe-KB based on three criteria: data quality, sequence coverage and resolution \cite{ELLAWAY_2024_CONFORMATIONS}. Despite this, representative chains might still be missing some residues present in other structures. To compare LIGYSIS binding sites to predicted sites on the representative chains, UniProt sequence mappings are needed for each residue in the LIGYSIS-defined sites. For this reason, LIGYSIS entries with ligand-binding residues missing UniProt residue mappings on the protein’s representative chain were discarded, resulting
in a set of 3048 human proteins, including 3448 segments. After predicting on these 3448 LIGYSIS chains, only chains where all residues across all predicted sites presented UniProt residue mapping were kept. This resulted in a final set of 2775 protein chains which was employed to assess the performance of the methods.

The performance of ligand binding site prediction methods can be evaluated at two different levels: \textit{residue} level, and \textit{pocket} level. Prediction at the residue level involves the discrimination of those residues that are likely to interact with a ligand, whereas the aim of pocket-level prediction is to define distinct regions on a protein, i.e., pockets, where \textit{a} ligand is likely to bind. This region can either be defined by a centroid, a group of cloud/grid points, a set of residues, or a combination of these. Some methods are \textit{residue}-centric, and first predict at the residue-level, use a threshold to select high-probability ligand-binding residues, and then cluster them into pockets. Residue-centric methods include IF-SitePred, or GrASP. Other (\textit{pocket}-centric) methods directly predict the location or shape of the pocket, without the need of predicting at the residue level first. Some of these methods can use their pocket-level prediction to report residue ligandability scores, e.g., P2Rank\textsubscript{CONS}, P2Rank, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} or Surfnet\textsuperscript{+}, and others, such as VN-EGNN, PUResNet, DeepPocket, or fpocket do not report residue ligandability scores.

\subsubsection{Residue-level predictions}

GrASP, P2RANK\textsubscript{CONS}, P2Rank, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+} all offer residue ligandability scores. Additionally, a ligandability score was derived for IF-SitePred using \autoref{eq:IFSP_score}. Prediction at the residue level is a binary classification problem: binding (1) or non-binding (0). Given a ligandability threshold $t_{LS}$, a residue with a ligandability score $LS_{i}$ is classified as ``positive'' if $LS_{i} > t_{LS}$. Conversely, the residue is classed as ``negative'' if $LS_{i} \leq t_{LS}$. Further stratification results from comparing the predictions to the LIGYSIS reference dataset.

\begin{itemize}
\item True Positive (TP): residue classified as positive that binds a ligand according to the reference.
\item False Positive (FP): residue classified as positive that does not bind a ligand in the reference.
\item True Negative (TN): residue classified as negative that does not bind a ligand.
\item False Negative (FN): residue classified as negative but is known to bind a ligand according to the reference.
\end{itemize}

With these four classes, true positive rate (TPR) (\autoref{eq:TPR}, false positive rate (FPR) (\autoref{eq:FPR}), precision (\autoref{eq:precision}) and recall (\autoref{eq:recall}) can be calculated and receiver operating characteristic (ROC) and precision-recall (PR) curves plotted. ROC and PR curves were obtained for each of the LIGYSIS protein chains. Using these curves, mean ROC and PR curves, representative of the variation across proteins for these metrics were obtained by taking the mean TPR and FPR (ROC curve) and mean precision and recall (PR curve) at each score interval. Mean area under the curve (AUC) for ROC and average precision (AP) were calculated by averaging the areas and precisions across curves. Baselines for these are 50\% and the proportion of true binding residues (10\%), respectively. ROC and AUC can't be calculated for VN-EGNN, PUResNet, DeepPocket, fpocket\textsubscript{PRANK} and fpocket as these methods do not provide residue ligandability scores.

\begin{equation}
\text{TPR (\%)} = 100 \times \frac{\text{TP}}{\text{TP} + \text{FN}}
\label{eq:TPR}
\end{equation}
\myequations{True Positive Rate}

\begin{equation}
\text{FPR (\%)} = 100 \times \frac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}}
\label{eq:FPR}
\end{equation}
\myequations{False Positive Rate}

\begin{equation}
\text{Precision (\%)} = 100 \times \frac{\text{TP}}{\text{TP} + \text{FP}}
\label{eq:precision}
\end{equation}
\myequations{Precision}

\begin{equation}
\text{Recall (\%)} = 100 \times \frac{\text{TP}}{\text{TP} + \text{FN}}
\label{eq:recall}
\end{equation}
\myequations{Recall}

Pocket binary labels (0: no pocket residue; 1: pocket residue) can determine TP, FP, TN and FN for each residue in a protein chain $P_i$. VN-EGNN, IF-SitePred, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+} do not report pocket residues. For these methods, residues within 6 \AA{} of the pocket centroid, cloud points and grid points (3$\times$), respectively, were labelled as pocket residues (1). All other residues in $P_i$ were labelled as non-binding (0). Across all residues in $P_i$, an F1 score was computed, which combines precision and recall into a unified metric, capturing the accuracy and completeness of predictions at the residue level (\autoref{eq:F1_score}). The Matthews Correlation Coefficient (MCC) \cite{MATTHEWS_1975_MCC} (\autoref{eq:MCC}) was also calculated. The median F1 score and MCC across the dataset proteins is reported for each method.

\begin{equation}
\text{F1} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\label{eq:F1_score}
\end{equation}
\myequations{F1 Score}

\begin{equation}
\text{MCC} = \frac{\text{TP} \times \text{TN} - \text{FP} \times \text{FN}}{\sqrt{(\text{TP} + \text{FP})(\text{TP} + \text{FN})(\text{TN} + \text{FP})(\text{TN} + \text{FN})}}
\label{eq:MCC}
\end{equation}
\myequations{Matthews Correlation Coefficient}

\subsubsection{Pocket-level predictions}

Ligand binding site prediction at the pocket level is a multi-instance prediction problem. There are no \textit{negatives} predicted at the pocket level of ligand binding site prediction, only \textit{positives}. A positive is a predicted pocket, which will be true (TP) or false (FP) depending on whether it is observed in the reference data. False negatives are those pockets observed in the reference data that are not predicted. They are the pockets the method fails to predict, and therefore, are not scored. A true negative would be a ``non-pocket'' that is \textit{not} predicted. This can't be quantified easily and even if it was, it would not be scored by the method, as it is not predicted. For this reason, in this context, neither TPR, nor FPR can be calculated. Consequently, ROC/AUC can't be utilised to assess ligand binding site prediction at the pocket level. False negatives are known, but not scored, and therefore PR/AUC is not an option either. What can be calculated is the recall given a certain criterion. In this case, because of the nature of the LIGYSIS dataset, where defined sites result from the clustering of multiple ligands, the distance between the predicted pocket centroid to the observed binding site (DCC) was chosen.

For each observed binding site in the LIGYSIS reference, the ``best'' prediction for each method was chosen. This is defined as the prediction with the minimum Euclidean distance to the observed pocket centroid or DCC. Once the observed-predicted pairs were obtained, only those with DCC $\leq$ 12 \AA{} were considered as correct predictions. A threshold of 12 \AA{} was chosen as 4 \AA{} is too strict a threshold when using DCC. A threshold of 4 \AA{} works well for the distance to closest ligand atom (DCA) but does not for DCC. The top-$N$ and $N$+2 ranking predictions were considered to calculate success rate, or recall (\autoref{eq:success_rate}), and maximum recall was calculated by considering all predictions, regardless of their score or rank. $N$ represents the number of observed sites for a given protein.

\begin{equation}
\text{Success rate (\%)} = 100 \times \frac{\text{observed sites with predicted site DCC} \leq 12 \text{Å}}{\text{observed sites}}
\label{eq:success_rate}
\end{equation}
\myequations{Success Rate}

Additionally, instead of conventional ROC, ROC100 \cite{WEBBER_2003_ROC100, SCOTT_2007_ROC100} was used to measure the predictive performance of the methods. To do this, for each method, all predictions across dataset proteins were ranked based on pocket score and cumulative true positives were plotted against cumulative false positives until 100 false positives were reached. In a similar way, a precision curve can be calculated by taking the top-$N$, in this case $N$ = 1000, predictions. This curve measures how precision changes as more predictions with lower scores are considered. This is indicative of how informative pocket scores are.

Precision and recall are key measures for evaluating the performance of ligand binding site prediction methods. However, these indicators are calculated and interpreted slightly differently depending on the context a prediction is analysed, i.e., pocket \textit{vs} residue level, as well as the metric employed, e.g., F1 score, MCC, ROC or PR curves. At the residue level, the prediction is a binary classification task, where each residue is classified as binding (1) or non-binding (0). Here, precision reflects the proportion of residues predicted as binding that are true, i.e., observed in the reference data. Recall measures the proportion of true binding residues that are correctly identified. For the calculation of F1 and MCC, a residue is labelled ``positive'' or ``negative'' depending on whether it is part of a predicted pocket. However, for ROC and PR curves, the positive and negative labels are derived based on a ligandability threshold, $t_{LS}$. Prediction at the pocket level represents a multi-instance prediction task. Precision indicates the proportion of predicted pockets that are observed in the reference data whilst recall represents the propostion of true binding pockets that are correctly predicted. It is important to  keep this in mind to correctly interpret precision and recall across different contexts.

\begin{figure}[htbp!]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ch_LBS_COMP/PNG/FIG13_VOLUME_OVERLAP_APPROACH.png}
    \caption[Relative Volume Overlap (RVO) calculation]{\textbf{Relative Volume Overlap (RVO) calculation.} \textbf{(A)} Example of two very accurate predictions by PUResNet and P2Rank on PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/4px2}{4PX2} \cite{PDB_4PX2}. Pocket volumes were calculated with POVME 2.0 and represented by coloured surfaces. These volumes result from the addition of unit volume spheres on a grid. To obtain the RVO, the intersection of these spheres between predicted and observed site was divided by the number of observed pocket spheres. Both predictions cover the entirety of the observed pocket volume; \textbf{(B)} GrASP and VN-EGNN predictions of a site on PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/2ZOX}{2ZOX} \cite{NOGUCHI_2008_STRUCTURE}. Th volumes of these predicted sites overlap less with the observed site: RVO = 67\% for GrASP and RVO = 1\%1 for VN-EGNN.}
    \label{fig:protein_RVO_approach}
\end{figure}

\FloatBarrier

To measure the similarity in shape and residue membership between predicted and observed pockets, relative residue overlap (RRO) and relative volume overlap (RVO) were employed. For an observed-predicted pocket pair, RRO represents the proportion of observed ligand-binding residues ($R_{o}$) that are covered by the predicted pocket residues ($R_{p}$) (\autoref{eq:RRO}). The POVME output was used for the calculation of RVO (\autoref{fig:protein_RVO_approach}). POVME defines the volume of a pocket as a series of equidistantly spaced spheres of unit volume. As predictions by the different methods were on the same coordinate reference, these pocket volume spheres were already aligned, and the volume overlap was calculated simply as the proportion of spheres in the observed pocket ($V_{o}$) that overlap with the predicted pocket spheres ($V_{p}$) (\autoref{eq:RVO}).

\begin{equation}
\text{RRO (\%)} = 100 \times \frac{|R_p \cap R_o|}{R_o}
\label{eq:RRO}
\end{equation}
\myequations{Relative Residue Overlap}

\begin{equation}
\text{RVO (\%)} = 100 \times \frac{|V_p \cap V_o|}{V_o}
\label{eq:RVO}
\end{equation}
\myequations{Relative Volume Overlap}

\subsection{Statistics and reproducibility}

VN-EGNN was installed and run locally from \url{https://github.com/ml-jku/vnegnn}. Likewise, for IF-SitePred: \url{https://github.com/annacarbery/binding-sites}. GrASP was obtained from \url{https://github.com/tiwarylab/GrASP} and predictions generated using the Google Colab Notebook. PUResNet predictions were obtained through the PUResNet v2.0 web server: \url{https://nsclbio.jbnu.ac.kr/tools/jmol}. DeepPocket was installed and executed locally: \url{https://github.com/devalab/DeepPocket}. P2Rank v2.4.2 was used to run all predictions as well as PRANK re-scoring: \url{https://github.com/rdk/p2rank}. fpocket v4.0 was installed via Conda: \url{https://anaconda.org/conda-forge/fpocket}. For PocketFinder, Ligsite and Surfnet, the ConCavity v0.1 ``+'' re-implementations were employed: \url{https://compbio.cs.princeton.edu/concavity/}.

Other recent methods including RefinePocket \cite{LIU_2023_REFINEPOCKET}, EquiPocket \cite{ZHANG_2024_EQUIPOCKET}, GLPocket \cite{LI_2023_GLPOCKET}, SiteRadar \cite{EVTEEV_2023_SITERADAR}, NodeCoder \cite{ABDOLLAHI_2023_NODECODER}, RecurPocket \cite{LI_2022_RECURPOCKET}, PointSite \cite{YAN_2022_POINTSITE}, DeepSurf \cite{MYOLNAS_2021_DEEPSURF}, Kalasanty \cite{STEPNIEWSKA_2020_KALASANTY}, BiteNet \cite{KOZLOVSKII_2020_BITENET}, GRaSP \cite{SANTANA_2020_GRaSP} or DeepSite \cite{JIMENEZ_2017_DEEPSITE} were not included in this analysis due to technical reasons. Peer-reviewed, open-source methods with publicly accessible code, clear installation instructions, well defined dependencies, and accessible command line interfaces were prioritised for this benchmark. This set of thirteen methods, counting \textsubscript{RESC} and \textsubscript{SEG} modes of DeepPocket is representative of the state-of-the-art within the field.

ChimeraX v1.7.1 \cite{PETTERSEN_2021_CHIMERAX} was used for structural visualisation in all figures unless otherwise stated, in which case PyMOL v2.5.2 was employed \cite{SCHRODINGER_2015_PYMOL}.

\subsection{Data and code availability}

The main results tables and files necessary to replicate the analysis described in this paper can be found here: \url{https://doi.org/10.5281/zenodo.13121414} \cite{UTGES_2024_LBSCOMP_ZENODO}. Software developed to carry out this analysis is found in this GitHub repository: \url{https://github.com/bartongroup/LBS-comparison} \cite{UTGES_2024_LBSCOMP_REPO}.

\section{Results}

\subsection{The LIGYSIS dataset}

The human subset of the LIGYSIS dataset, LIGYSIS\textsubscript{HUMAN}, comprises protein-ligand complexes for 3448 human proteins. For each protein, biologically relevant protein-ligand interactions, in accordance with BioLiP \cite{YANG_2013_BIOLIP}, are considered across the PISA-defined \cite{KRISSINEL_2007_PISA} biological assemblies of the multiple entries deposited in the PDBe \cite{ARMSTRONG_2020_PDBE}. Ligands are clustered using their protein interaction fingerprint to identify ligand binding sites as described in CROSS-REFERENCE TO LIGYSIS CHAPTER!!!. The full LIGYSIS dataset includes $\approx$30,000 proteins with known ligand-bound complexes. Here, the human subset of LIGYSIS is employed as a manageable set to run all prediction methods on and referred to as \textit{LIGYSIS} for brevity.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG1_REDUNDANT_PLIS_SPLIT_1.png}
    \caption[Redundancy in protein-ligand interfaces (I)]{\textbf{Redundancy in protein-ligand interfaces (I).} For PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1jqy}{1JQY}, the asymmetric unit comprises three copies of a homo-pentamer, whereas the biologically functional assembly is a single pentamer. An \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/A32}{A32} ligand molecule binds to each copy, except for one, of each of the three pentamers. This results in the same protein-ligand interface repeated 14 times, i.e., 14$\times$ redundancy. Dashed rectangles indicate the asymmetric and biological units.}
    \label{fig:redundant_plis_1}
\end{figure}

The LIGYSIS dataset differs from previous train and test sets for ligand binding sites by considering biological units, aggregating multiple structures of the same protein and removing redundant protein-ligand interfaces. The asymmetric unit is the smallest portion of a crystal structure that can reproduce the complete unit cell through a series of symmetry operations. The asymmetric unit often does not correspond to the biological assembly or unit and relying on it can lead to artificial crystal contacts or redundant protein-ligand interfaces. The biological unit is the biologically relevant and functional macromolecular assembly for a given structure and might be formed by one, multiple copies or a portion of the asymmetric unit \cite{XU_2019_ASSEMBLIES}. LIGYSIS consistently considers biological units, which is key in any analysis that delves into molecular interactions at residue or atomistic level. An example of this illustrated in \autoref{fig:redundant_plis_1} is PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1jqy}{1JQY} \cite{PICKENS_2002_ANCHOR}, part of the HOLO4K dataset, where the asymmetric unit is formed by three copies of a homo-pentamer, whereas the biological unit comprises a single pentamer. In this structure, 14 molecules of BMSC-0010 (\href{https://www.rcsb.org/ligand/A32}{A32}) interact with 14 copies of \textit{Escherichia coli} heat-labile enterotoxin B chain (\href{https://www.uniprot.org/uniprotkb/P32890/entry}{P32890}). This protein-ligand interface is the same repeated 14 times.

\FloatBarrier

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG1_REDUNDANT_PLIS_SPLIT_2.png}
    \caption[Redundancy in protein-ligand interfaces (II)]{\textbf{Redundancy in protein-ligand interfaces (II).} For PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1PPR}{1PPR} both the asymmetric and biological units are a homo-trimer. Different molecules of the same ligands are binding to the same interfaces across the three copies of the trimer, i.e., 3$\times$ redundancy. Dashed rectangle indicate the asymmetric and biological units.}
    \label{fig:redundant_plis_2}
\end{figure}

Protein-ligand interface redundancy can also be an issue when the asymmetric unit equals the biological assembly (\autoref{fig:redundant_plis_2}). In PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1PPR}{1PPR} \cite{HOFMANN_1996_CAROTENOID}, also in HOLO4K, molecules of chlorophyll A (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/CLA}{CLA}), peridinin (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/PID}{PID}) and digalactosyl diacyl glycerol (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/DGD}{DGD}) bind to the three copies of a peridinin-chlorophyll a-binding protein 1, chloroplastic, PCP, (\href{https://www.uniprot.org/uniprotkb/P80484/entry}{P80484}) trimer, resulting in a redundancy of 3$\times$. To account for this, LIGYSIS considers unique non-redundant protein-ligand interfaces by retrieving the UniProt sequence numbers of the residues the ligands interact with, so 1/14 interfaces would be retrieved for PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1JQY}{1JQY} and 12/36 for PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/1PPR}{1PPR}. Finally, unique ligand interactions are aggregated across different structures for the same protein and ligand sites defined.

\FloatBarrier

%\begin{figure}[htbp!]
%    \centering
%    \includegraphics[width=0.9\textwidth]{figures/ch_LBS_COMP/MAIN/PDF/FIG1_REDUNDANT_PLIS_OPT.pdf}
%    \caption[Redundancy in protein-ligand interfaces]{\textbf{Redundancy in protein-ligand interfaces.} %Two examples of how the type of macromolecular assembly and difference between the asymmetric and %biological unit of a protein-ligand complex results in redundant protein-ligand interfaces. %\textbf{(A)} For PDB: 1QJY, the asymmetric unit comprises three copies of a homo-pentamer, whereas the %biologically functional assembly is a single pentamer. A BMSC-0010 ligand molecule binds to each copy, %except for one, of each of the three pentamers. This results in the same protein-ligand interface %repeated 14 times, i.e., 14x redundancy; \textbf{(B)} For PDB: 1PPR both the asymmetric and biological %units are a homo-trimer. Different molecules of the same ligands are binding to the same interfaces %across the three copies of the trimer, i.e., 3x redundancy. Dashed rectangles indicate the asymmetric/%biological units.}
%    \label{fig:redundant_plis}
%\end{figure}

\autoref{fig:PDBbind_VS_LIGYSIS} shows the comparison between PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/4GQQ}{4GQQ} \cite{WILLIAMS_2012_AMYLASE}, present in the PDBbind dataset, and the LIGYSIS entry for human pancreatic alpha-amylase (\href{https://www.uniprot.org/uniprotkb/P04746/entry}{P04746}), which representative structure is also \href{https://www.ebi.ac.uk/pdbe/entry/pdb/4GQQ}{4GQQ}. The entry in PDBbind represents a single protein-ligand complex, whereas LIGYSIS makes use of 51 structures, 195 ligands to define 13 different ligand binding sites. LIGYSIS aggregates all unique biologically relevant protein-ligand interactions for a protein in a non-redundant manner, thus representing the most complete and integrative protein-ligand binding dataset up to date. For this reason, LIGYSIS is proposed as a new benchmark dataset for the prediction of ligand binding sites and used in this chapter to evaluate a set of thirteen ligand binding site prediction and cavity identification tools.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ch_LBS_COMP/PNG/FIG2_LIGYSIS_vs_PDBbind.png}
    \caption[Comparison of PDBbind and LIGYSIS]{\textbf{Comparison of PDBbind and LIGYSIS.} PDBbind is comprised by complexes between a protein and the most biologically relevant ligand in a structure. For PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/4GQQ}{4GQQ}, this is ethyl caffeate (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/0XR}{0XR}). LIGYSIS considers all unique biologically relevant protein-ligand interactions across all the structures for a given protein. For human pancreatic alpha-amylase (\href{https://www.uniprot.org/uniprotkb/P04746/entry}{P04746}), which representative structure is \href{https://www.ebi.ac.uk/pdbe/entry/pdb/4GQQ}{4GQQ}, 13 ligand binding sites are defined from 195 ligands across 51 structures. LIGYSIS provides a better representation of the ligand-binding capabilities of a protein than a single protein-ligand complex and constitutes therefore a better benchmark for ligand binding site prediction tools.}
    \label{fig:PDBbind_VS_LIGYSIS}
\end{figure}

\begin{landscape}
\begin{longtable}{|M{24mm}|M{20mm}|M{27mm}|M{20mm}|M{25mm}|M{25mm}|M{58mm}|}
\hline
\textbf{Dataset}    & \textbf{Type}  & \textbf{\# Structures} & \textbf{\# Sites} & \textbf{\# Ligands} & \textbf{Overlap} (\%) & \textbf{Methods}                                      \\ \hline
\endfirsthead
%
\endhead
%
LIGYSIS    & NEW   & 3448         & 8244    & \textbf{\textcolor{CBBlue}{65,116}}     & --          & --                                            \\ \hline
LIGYSIS\textsubscript{NI}  & NEW   & 2275         & 4572    & 38,595     & --          & --                                            \\ \hline
sc-PDB\textsubscript{FULL} & TRAIN & \textbf{\textcolor{CBBlue}{17,594}}        & \textbf{\textcolor{CBBlue}{17,594}}   & 17,594     & \textbf{\textcolor{CBOrange}{801 (9.7)}}        & VN-EGNN, GrASP, PUResNet, DeepPocket         \\ \hline
bMOAD\textsubscript{SUB}   & TRAIN & 5899         & 11,184   & 11,184     & 606 (7.6)        & IF-SitePred                                  \\ \hline
CHEN11     & TRAIN & \textbf{\textcolor{CBOrange}{244}}           & \textbf{\textcolor{CBOrange}{479}}      & \textbf{\textcolor{CBOrange}{479}}        & \textbf{\textcolor{CBBlue}{40 (0.5)}}        & PRANK, P2Rank                                       \\ \hline
PDBbind\textsubscript{REF} & TEST  & 5316         & 5316    & 5316      & 310 (3.8)        & VN-EGNN                                      \\ \hline
SC6K       & TEST  & 6147         & 6147    & 6147      & 259 (3.1)        & DeepPocket                                   \\ \hline
HOLO4K     & TEST  & 4009         & 10,175   & 10,175     & 207 (2.5)        & \textit{ALL*}                                         \\ \hline
COACH420   & TEST  & 413           & 624      & 624        & 41 (0.5)        & VN-EGNN, GrASP, DeepPocket, PUResNet, P2Rank \\ \hline
JOINED   & TEST  & 557           & 752      & 752        & 110 (1.3)        & PRANK \\ \hline
\caption[Datasets summary statistics]{\textbf{Datasets summary statistics.} \# Structures, \# Sites and \# Ligands represent the number of PDB structures, ligand sites and total number of ligands for each dataset. For LIGYSIS and LIGYSIS\textsubscript{NI}, 3448 and 2775, are the number of structural segments, each represented by a single chain. For each segment, biologically relevant ligands across structures were considered: $N$ = 23,321 (LIGYSIS) and $N$ = 19,012 (LIGYSIS\textsubscript{NI}). The number of ligands is not equal to the number of sites for LIGYSIS, as ligands from multiple structures of the same protein are aggregated into unique sites. Overlap is the number of LIGYSIS binding sites represented by at least one protein-ligand complex for a given dataset. Percentage relative to LIGYSIS also reported. Methods represents the ligand site predictors that use these datasets for training or test. For \# Structures, \# Sites and \# Ligands, highest values are coloured in bold blue font and lowest in orange. This is the other way around for Overlap.}
\label{tab:datasets_comp}\\
\end{longtable}
\end{landscape}

\subsection{Comparison of datasets}

To assess the scope and limitations of the predictive methods surveyed in this chapter, their training and test sets were compared with LIGYSIS by number of sites per protein, number of interacting protein chains per ligand site, ligand size, ligand site size, and ligand composition. sc-PDB\textsubscript{FULL} represents the full sc-PDB dataset used for training by DeepPocket, bMOAD\textsubscript{SUB} the subset of binding MOAD used for training by IF-SitePred and PDBbind\textsubscript{REF} the reference subset of PDBbind which VN-EGNN uses for testing. Only original versions of each dataset are considered in this analysis e.g., HOLO4K, but not HOLO4K\textsubscript{Mlig}, nor HOLO4K\textsubscript{Mlig+} HAP, or HAP-small. The same goes for Mlig and Mlig+ versions of COACH420, sc-PDB\textsubscript{SUB} and sc-PDB\textsubscript{RICH}. \textit{ALL*} represents all methods in this work except for fpocket, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+}. \autoref{tab:datasets_comp} summarises the size of the datasets, which methods employ them and their overlap with the LIGYSIS set. LIGYSIS differs from all other datasets since biologically relevant ions are considered, comprising $\approx$ 40\% of the ligand sites. For additional reference, LIGYSIS\textsubscript{NI}, a subset of LIGYSIS without ions, is also included in this analysis. \autorefpanel{fig:dataset_comp_1}{A} shows the number of binding sites per entry across datasets. sc-PDB\textsubscript{FULL}, PDBbind\textsubscript{REF} and SC6K only consider the most relevant ligand for each entry. COACH420 and JOINED mostly present single-ligand entries ($\approx$70\%). bMOAD\textsubscript{SUB} (46\%) and CHEN11 (58\%) present more similar distributions to LIGYSIS, where 54\% of the protein chains present more than one binding site. This percentage decreases for LIGYSIS\textsubscript{NI} (38\%) as ion sites are removed. HOLO4K presents the highest proportion (62\%) of multi-ligand entries. Both HOLO4K and COACH420 are based on asymmetric units, and not biological assemblies. For HOLO4K, 1811 (40\%) of structures present different numbers of chains between the asymmetric and biological units. This is even more frequent in COACH420: 234 (56\%). Moreover, multimeric complexes might present the same protein-ligand interface repeated across the copies of the complex (\autoref{fig:redundant_plis_1}, \autoref{fig:redundant_plis_2}). Considering predictions of these interfaces as independent can lead to overestimating the performance of a predictor. Regarding the number of chains interacting with a given ligand (\autorefpanel{fig:dataset_comp_1}{B}), CHEN11 and COACH420 present the smaller fraction of multimeric protein-ligand interactions: 3\% and 6\%, respectively, whereas SC6K presents the highest (44\%). The rest of the methods range between 20-30\%. There are no striking differences regarding the size of the interacting protein chains, represented by the number of residues (\autorefpanel{fig:dataset_comp_1}{C}).

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG3_DATASET_COMPARISON_SPLIT_1.png}
    \caption[Comparison of datasets (I)]{\textbf{Comparison of datasets (I).} Panels A, B, C, E and F plot the frequencies (\%) of binned intervals of a discrete variable, coloured using the \textit{cividis} palette. Interval ranges were selected to facilitate data interpretation. \textbf{(A)} Number of ligand binding sites per dataset entry; \textbf{(B)} Number of ligand-interacting protein chains. This represents whether the ligand interacts with a single protein chain or more; \textbf{(C)} Length of ligand-interacting protein chains (number of amino acids); \textbf{(D)} Ligand molecule type frequency as described in the CCD; \textbf{(E)} Number of ligand atoms; \textbf{(F)} Binding site size, i.e., number of ligand-interacting protein residues. Dashed lines drawn at frequency = 50\%. A subset of LIGYSIS with no ions (NI), LIGYSIS\textsubscript{NI}, is included in this analysis, as most training and test datasets do not consider ions.}
    \label{fig:dataset_comp_1}
\end{figure}

\autorefpanel{fig:dataset_comp_1}{D} represents the ligand type composition of the datasets. Non-polymer ligands dominate all datasets ($>$66\%), and the proportion of peptides and nucleic acids differ across datasets, with JOINED and LIGYSIS presenting fewer ligands of these types (0.9\% and 1.6\%). sc-PDB\textsubscript{FULL} and SC6K are depleted in saccharides ($<$1\%). \autorefpanel{fig:dataset_comp_1}{E} depicts the difference in the number of atoms of the ligands in each dataset. LIGYSIS is, as expected, different due to its ion ligand content, however, there is no difference between LIGYSIS\textsubscript{NI} and the other datasets. \autorefpanel{fig:dataset_comp_1}{F} conveys the difference in the number of ligand-interacting residues. LIGYSIS has the largest proportion of small sites, 1-10 residues, (56\%). This is directly related to the prominent ion component, and the frequency decreases when ions are removed (LIGYSIS\textsubscript{NI}: 36\%). CHEN11, COACH420, JOINED and HOLO4K are more similar to LIGYSIS\textsubscript{NI}, whereas sc-PDB\textsubscript{FULL}, PDBbind\textsubscript{REF} and SC6K are clearly different and present almost exclusively large sites, larger than 20 amino acids, ($>$90\%).

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG3_DATASET_COMPARISON_SPLIT_2.png}
    \caption[Comparison of datasets (II)]{\textbf{Comparison of datasets (II).} Five most frequent ligands per dataset. Error bars represent 95\% confidence interval of the proportion \cite{WILSON_197_PROP_CI}. Ligands of similar type are coloured in shades of the same colour: greens for ions, reds for co-factors, blues for energy-carrier molecules, yellows for sugars, grey for peptides and white for other non-polymeric ligands. Above the bars, Shannon Entropy and the proportion of all ligands in each set covered by these top-5 can be found. Both are measures of ligand diversity within each dataset. LIGYSIS\textsubscript{NI}, a subset of LIGYSIS without ions is included in this analysis, as most training and test datasets do not consider ions. \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/017}{017}: Darunavir; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/ADE}{ADE}: adenine; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/BGC}{BGC}: glucose; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/CLR}{CLR}: cholesterol; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/GAI}{GAI}: guanidine; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/GSH}{GSH}: glutathione; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/MAN}{MAN}: mannose; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/FUC}{FUC}: fucose; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/NAP}{NAP}: nicotinamide-adenine-dinucleotide phosphate; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/SAH}{SAH}: S-Adenosyl-L-homocysteine; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/FMN}{FMN}: Flavin mononucleotide; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/GAL}{GAL}: galactose; N-mer: protein peptides of N amino acids; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/PLP}{PLP}: Vitamin B6 phosphate; \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/XYP}{XYP}: xylose.}
    \label{fig:dataset_comp_2}
\end{figure}

\autoref{fig:dataset_comp_2} explores the ligand diversity on each dataset by showing the top-5 most frequent ligands per dataset, the percentage of the total number of ligands they represent, as well as Shannon entropy $H'$. Shannon entropy is a measure of diversity. Larger numbers indicate a more evenly spread distribution of a larger number of different molecules, whereas small numbers indicate higher frequency of a few ligands. While four out of the top-5 ligands of LIGYSIS are ions -- Zn\textsuperscript{+2} (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/ZN}{ZN}), Ca\textsuperscript{+2} (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/CA}{CA}), Mg\textsuperscript{+2} (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/MG}{MG}), Mn\textsuperscript{+2} (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/MN}{MN}) -- and represent 19.2\% of all ligands, its diverse composition is comparable to that of PDBbind\textsubscript{REF}. Removing ions, LIGYSIS\textsubscript{NI} becomes the most diverse dataset with $H'$ = 8.8 and its top-5 ligands only covering 5.3\% of all ligands in the set. SC6K is the least diverse with its top-5 most frequent ligands covering 33\% of all ligands. All datasets, except for LIGYSIS, LIGYSIS\textsubscript{NI}, and PDBbind\textsubscript{REF}, are dominated by co-factor ligands, such as flavin-adenine dinucleotide (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/FAD}{FAD}), nicotinamide-adenine dinucleotide (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/NAD}{NAD}), and haem (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/HEM}{HEM}) or energy carrier molecules such as adenine tri-, di- and monophosphate (\href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/ATP}{ATP}, \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/ADP}{ADP}, \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/AMP}{AMP}). Short peptides ($<$10 aas) are the most common ligands in PDBbind\textsubscript{REF} (5\%), and energy carriers represent $<$2\% of the top-5 ligands. Cholesterol, mannose and fucose are some of the most common ligands in LIGYSIS\textsubscript{NI}. For all further analysis, including characterisation of binding pockets and performance evaluation of the prediction methods, LIGYSIS, i.e., including ions, was utilised.

\subsection{Binding pocket characterisation}

After removing backbone-only chains and those with missing residue mapping to UniProt, the final LIGYSIS set which was employed for the benchmark of the methods comprises 2,775 representative chains. Not all methods predict pockets on all the chains. VN-EGNN, GrASP, fpocket, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+}, and Surfnet\textsuperscript{+} predict in $>$99\% of the chains, P2Rank\textsubscript{CONS} on 93\%, followed by P2Rank on 86\%, PUResNet and DeepPocket\textsubscript{SEG} (85\%), and finally IF-SitePred only predicts pockets on 75\% of the chains. PUResNet, DeepPocket, P2Rank\textsubscript{CONS} and P2Rank often don't predict on smaller proteins ($<$100 amino acids) as well as non-globular or elongated proteins, representing 60-80\% of proteins with no predicted pockets. However, for IF-SitePred larger globular proteins represent $\approx$50\% of all proteins where this method fails to predict a pocket (\autoref{fig:missed_preds_prot_class}). Predicted residue ligandability scores for P2Rank\textsubscript{CONS}, P2Rank and IF-SitePred (which we derived in this work), were examined for the proteins with no predicted pockets. \autoref{fig:ifsp_missed_preds} illustrates 8 examples of proteins where residues with IF-SitePred (\autoref{eq:IFSP_score}) high ligandability scores cluster in space into clear binding sites that are not reported as predictions by this method. This suggests that IF-SitePred is too strict in selecting only those residues predicted as ligand-binding by all 40 models. The cloud point selection clustering approach or threshold in this method may also play a role in this.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.60\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG1_MISSED_PREDS_PROT_CLASS.png}
    \caption[Where methods do not predict any sites]{\textbf{Where methods do not predict any sites.} IF-SitePred does not predict any ligand binding sites on 700 of the 2775 protein chains in the LIGYSIS set (25\%), PUResNet on 415 (15\%), DeepPocket\textsubscript{SEG} (426; 15\%), P2Rank\textsubscript{CONS} (196; 7\%) and P2Rank (373; 13\%). All methods struggle to predict on elongated proteins, regardless of their size, as well as on tiny globular proteins. Globular proteins comprise the most common group amongst the proteins with no predictions for IF-SitePred (53\%). Dashed line indicates frequency of 50\%.}
    \label{fig:missed_preds_prot_class}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG4_IFSP_MISSED_PREDICTIONS.png}
    \caption[IF-SitePred ``missed'' predictions]{\textbf{IF-SitePred ``missed'' predictions.} Eight examples of human protein chains where IF-SitePred does not report any predicted ligand binding sites. Predictions are made on ligand-stripped chains. Ligand molecules, in orange, are superposed to illustrate how the ligandability scores recapitulate the observed binding site. These are protein representative chains and ligand molecules might not be observed in the same entry; \textbf{(A)} GDP-fucose protein O-fucosyltransferase 2, \href{https://www.uniprot.org/uniprotkb/Q9Y2G5/entry}{Q9Y2G5}, with \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/GFB}{GFB} superimposed (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/4ap6}{4AP6}) \cite{CHEN_2012_POFUT2}; \textbf{(B)} tRNA (cytosine(72)-C(5))-methyltransferase NSUN6, \href{https://www.uniprot.org/uniprotkb/Q8TEA1/entry}{Q8TEA1}, (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5WWT}{5WWT}) \cite{LIU_2017_NSUN6} with superposed \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/SFG}{SFG} (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5WWR}{5WWR}) \cite{LIU_2017_NSUN6}; \textbf{(C)} Tubulin beta-2B chain, \href{https://www.uniprot.org/uniprotkb/Q9BVA1/entry}{Q9BVA1}, with \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/G2P}{G2P} (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/7ZCW}{7ZCW}) \cite{RAMIREZ_2023_VASH2}; \textbf{(D)} Cyclic GMP-AMP phosphodiesterase SMPDL3A, \href{https://www.uniprot.org/uniprotkb/Q92484/entry}{Q92484}, with \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/C5P}{C5P} (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5EBE}{5EBE}) \cite{LIM_2016_SPHINGOMYELIN}; \textbf{(E)} tRNA (adenine(58)-N(1))-methyltransferase catalytic subunit, \href{https://www.uniprot.org/uniprotkb/Q96FX7/entry}{Q96FX7}, with \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/SAH}{SAH} (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5CCB}{5CCB}) \cite{FINER_2015_tRNA}; \textbf{(F)} Chronophin, \href{https://www.uniprot.org/uniprotkb/Q96GD0/entry}{Q96GD0}, (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/5gyn}{5GYN}) \cite{PDB_5GYN} with \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/PLP}{PLP} (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/2FCT}{2FCT}) \cite{BLASIAK_2006_SYRB2}; \textbf{(G)} Mitochondrial Methylmalonic aciduria type A protein, \href{https://www.uniprot.org/uniprotkb/Q8IVH4/entry}{Q8IVH4}, with \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/GDP}{GDP} (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/8GJU}{8GJU}) \cite{MASCARENHAS_2023_GPROTEIN}; \textbf{(H)} Renalase, \href{https://www.uniprot.org/uniprotkb/Q5VYX0/entry}{Q5VYX0}, (PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/3QJ4}{3QJ4}) with \href{https://www.ebi.ac.uk/pdbe-srv/pdbechem/chemicalCompound/show/FAD}{FAD} \cite{MILANI_2011_NADP}. Residues are coloured based on the ligandability score calculated by averaging the probabilities predicted by each of the 40 IF-SitePred prediction models. This is a score ranging 0-1 which is indicative of the likelihood of a given residue binding a ligand. Clear pockets can be observed formed by residues with high ligandability scores (darker blue colour), which agree with the sites where ligands bind.}
    \label{fig:ifsp_missed_preds}
\end{figure}

\autoref{tab:pocket_features_stats} summarises the ligand site characterisation analysis. fpocket predicts the most sites out of all the methods, with 57,859, followed by IF-SitePred (44,948), DeepPo-cket\textsubscript{SEG} (21,718), VN-EGNN (13,582), P2Rank (12,412), P2Rank\textsubscript{CONS} (10,180), Surfnet\textsuperscript{+} (9043), PocketFinder\textsuperscript{+} (8913), Ligsite\textsuperscript{+} (6903), GrASP (4694) and PUResNet, which predicts fewest sites (2621). LIGYSIS defines 6882 binding sites from experimental data. Relative to LIGYSIS, the prediction methods have ratios of predicted/defined sites ranging from 8.4 (fpocket) to 0.4 (PUResNet) with P2Rank\textsubscript{CONS} in the middle, predicting 1.5 pockets per observed reference site. IF-SitePred, DeepPocket\textsubscript{SEG} as well as P2Rank and fpocket predict more pockets on larger protein chains, whereas the rest of methods do not (\autoref{fig:sites_vs_prot_size}). This effect is most clear with fpocket, which predicts 350 pockets for chain A of PDB: \href{https://www.ebi.ac.uk/pdbe/entry/pdb/7SUD}{7SUD} \cite{LIU_2022_DNAPK}, a structure of the DNA-dependent protein kinase catalytic subunit, DNPK1, (\href{https://www.uniprot.org/uniprotkb/P78527/entry}{P78527}) with 3736 amino acid residues. In contrast, VN-EGNN, which initially places $K$ = 8 virtual nodes, results in a maximum of 8 predicted pockets, regardless of protein chain size, and PUResNet predicts a single pocket in 90\% of the protein chains. 

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG2_POCKETS_VS_PROTEIN_SIZE.png}
    \caption[Number of pockets \textit{vs} protein size]{\textbf{Number of pockets \textit{vs} protein size.} Number of defined (LIGYSIS) and predicted sites against protein chain size, i.e., number of amino acid residues. Number of residues has been discretised into intervals of 50 until 650, and larger intervals until the maximum, $\approx$3800. Error bars represent one standard deviation (SD).}
    \label{fig:sites_vs_prot_size}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG5_BINDING_POCKET_FEATURES_SPLIT_1.png}
    \caption[Binding pocket characterisation (I)]{\textbf{Binding pocket characterisation (I).} Violin plots show the main distributions and swarm plots are used to show outliers. Data points farther than four standard deviations (SD) from the mean are considered outliers. The limit of the Y axis is the maximum non-outlier value plus a buffer value. This way, only the most extreme outliers are hidden, which maximises visual interpretation of the data whilst minimising the number of data points not shown. Within the violin plots are box plots representing the underlying distribution. Line represents the median, box contains the interquartile range (IQR), and whiskers extend to 1.5 $\times$ IQR. \textbf{(A)} Number of pockets per protein; \textbf{(B)} Pocket radius of gyration $R_{g}$ (\AA{}).}
    \label{fig:pocket_features_1}
\end{figure}

\autoref{fig:pocket_features_1} and \autoref{fig:pocket_features_2} represent how the eleven sets of unique ligand site predictors compare to each other as well to LIGYSIS, which \textit{defines} ligand sites from experimentally determined biologically relevant protein-ligand complexes. There are eleven unique sets of predictions since DeepPocket\textsubscript{RESC} and fpocket\textsubscript{PRANK} do not predict, their own pockets, but re-score and re-rank original fpocket predictions. DeepPocket\textsubscript{SEG} predictions are different as new pocket shapes are extracted by the CNN segmentation module. \autorefpanel{fig:pocket_features_2}{A} shows how PUResNet, VN-EGNN and GrASP differ from the other methods with a maximum of 4, 7 and 12 predicted pockets, respectively. PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+} present narrow distributions like LIGYSIS and with medians of 1-3 pockets per protein. P2Rank\textsubscript{CONS} and P2Rank also present a median of 3 pockets per protein but display wider distributions as they can predict up to 60 and 80 pockets per protein, respectively. Overall, P2Rank\textsubscript{CONS} predicts fewer pockets than P2Rank. DeepPocket\textsubscript{SEG}, fpocket and IF-SitePred follow, with a median of 6, 17 and 20 pockets. The difference in number of pockets between DeepPocket\textsubscript{SEG} and DeepPocket\textsubscript{RESC} or fpocket is because 60\% of fpocket candidates are not extracted by the CNN segmentation module implemented in DeepPocket.

\autorefpanel{fig:pocket_features_1}{B} shows the distribution of pocket radius of gyration, $R_{g}$. VN-EGNN and IF-SitePred differ from the rest of methods with narrow distributions and medians around 6 \AA{}. These two methods do not report pocket residues. Instead, they were obtained using a distance threshold of 6 \AA{} from the centroid, for VN-EGNN, and cloud points, for IF-SitePred. This is reflected by examining the percentage of pockets with $R_{g} >$ 10 \AA{} which is 0\% and 0.1\% for VN-EGNN and IF-SitePred. This is a striking difference compared to the LIGYSIS reference and other methods: 1.8\% (fpocket), 4.8\% (P2Rank), 5.7\% (DeepPocket\textsubscript{SEG}), 6.4\% (GrASP), 6.5\% (P2Rank\textsubscript{CONS}), 11.6\% (PUResNet), 12.6\% (LIGYSIS), 16\% (Surfnet\textsuperscript{+}), 21.4\% (PocketFinder\textsuperscript{+}) and 33.5\% (Ligsite\textsuperscript{+}). The latter three predict the sites with largest median $R_{g} \approx$ 9 \AA{}. VN-EGNN, GrASP, PUResNet and DeepPocket\textsubscript{SEG} predict sites with $R_{g}$ = 0 \AA{}. This is rather infrequent (7.8\% GrASP) and $<$3\% for the other three. These examples correspond to singletons, i.e., pockets formed by only one amino acid.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG5_BINDING_POCKET_FEATURES_SPLIT_2.png}
    \caption[Binding pocket characterisation (II)]{\textbf{Binding pocket characterisation (II).} Violin plots show the main distributions and swarm plots are used to show outliers. Data points farther than four standard deviations (SD) from the mean are considered outliers. The limit of the Y axis is the maximum non-outlier value plus a buffer value. This way, only the most extreme outliers are hidden, which maximises visual interpretation of the data whilst minimising the number of data points not shown. Within the violin plots are box plots representing the underlying distribution. Line represents the median, box contains the interquartile range (IQR), and whiskers extend to 1.5 $\times$ IQR. \textbf{(A)} Minimum inter-pocket centroid distance (MCD) (\AA{}). This is a measure of how close predicted pockets are to each other within a protein; \textbf{(B)} Maximum inter-pocket residue overlap (MRO). Residue overlap was calculated as Jaccard Index. This is a measure of how much the pockets overlap in terms of binding residues.}
    \label{fig:pocket_features_2}
\end{figure}

\autorefpanel{fig:pocket_features_2}{A} illustrates how close predicted sites are to each other within a protein chain. Pairwise distances between the centroids of all ligand site pairs for a protein are calculated, and for each site, the minimum distance is taken. Sites predicted by VN-EGNN, IF-SitePred and DeepPocketSEG are very close to each other, with median distances ($\tilde{d}$) of 1.1, 3.4 and 4.6 \AA{}, respectively. fpocket follows with $\tilde{d}$ = 9.7 \AA{}. The rest of the methods and LIGYSIS (reference) present median distances ranging between 13-18 \AA{} (LIGYSIS, P2Rank\textsubscript{CONS}, P2Rank, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+}, Surfnet\textsuperscript{+}), and finally GrASP ($\tilde{d}$ = 21.7 \AA{}) and PUResNet ($\tilde{d}$ = 27 \AA{}). Both versions of P2Rank present the most similar distribution to what is observed on LIGYSIS.

\autorefpanel{fig:pocket_features_2}{B} depicts the overlap existing between residues that form the predicted pockets within a protein. All pairwise overlaps, i.e., Jaccard Index, are calculated between pockets in a chain, and for each pocket, the maximum is taken. This is a measure of how much predicted pockets overlap with each other. This is directly related to how close pockets are, and so VN-EGNN, IF-SitePred and DeepPocket\textsubscript{SEG} present very high overlaps $\tilde{o}$ = 0.85, $\tilde{o}$ = 0.55 and $\tilde{o}$ = 0.4, respectively. fpocket follows with $\tilde{o}$ = 0.15, Ligsite\textsuperscript{+} ($\tilde{o}$ = 0.09), Surfnet\textsuperscript{+} ($\tilde{o}$ = 0.07), P2Rank\textsubscript{CONS}, P2Rank and PocketFinder\textsuperscript{+} ($\tilde{o}$ = 0.05), and finally LIGYSIS, GrASP and PUResNet with $\tilde{o}$ = 0. GrASP is the only method of the thirteen presented here that clusters atoms directly, and as a result, overlap between pockets is minimised. Other methods cluster cloud points (IF-SitePred), SAS points (P2Ranks), voxels (PUResNet, DeepPocket), alpha spheres (fpocket), or grid points (PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+}, Surfnet\textsuperscript{+}) but not residues, resulting consequently in higher overlapping.

Proximity in space between predicted sites as well as residue overlap are indicators of redundant ligand binding site prediction, i.e., duplicate predictions of a unique observed ligand site. This is the case for VN-EGNN, IF-SitePred and DeepPocket\textsubscript{SEG}. This phenomenon could negatively impact the precision and recall of these methods. Accordingly, correcting for redundancy should have a significant impact on the performance of these methods. In contrast, GrASP and PUResNet which predict a small can of pockets show low proximity and overlap of predicted sites and so redundancy is not an issue.

% Please add the following required packages to your document preamble:
% \usepackage{lscape}
% \usepackage{longtable}
% Note: It may be necessary to compile the document several times to get a multi-page table to line up properly
\begin{landscape}
\begin{longtable}[c]{|M{28mm}|M{29mm}|M{29mm}|M{41mm}|M{26mm}|M{26mm}|M{20mm}|}
\hline
\textbf{Method}        & \textbf{Coverage} (\%)    & \textbf{\# Total Pockets}  & \textbf{\# Pockets per protein} & \textbf{R\textsubscript{g}} (\AA{}) & \textbf{MCD} (\AA{}) & \textbf{MRO}  \\ \hline
\endfirsthead
%
%\multicolumn{7}{c}%
%{{\bfseries Table \thetable\ continued from previous page}} \\
%\hline
%\textbf{Method}        & \textbf{\% Coverage}    & \textbf{Total Pockets}  & \textbf{Pockets per protein} & \textbf{$R_{g}$ (\AA{})} & \textbf{MCD (\AA{})} & \textbf{MRO}  \\ \hline
\endhead
%
LIGYSIS       & 2775          & 6882          & 1, 1, 27            & 5.9                              & 14.1                         & 0    \\ \hline
VN-EGNN       & 2764 (99.6\%)   & 13,582 ($\times$2.0) & 1, 5, 7             & 5.9                              & \textbf{1.1}                          & \textbf{0.85} \\ \hline
IF-SitePred   & \textbf{2075 (74.8\%}) & 44,948 ($\times$6.5) & 1, \textbf{20}, 129          & 5.9                              & 3.4                          & 0.55 \\ \hline
GrASP         & 2771 (99.9\%) & 4694 ($\times$0.7)  & 1, 1, 12            & 7.9                              & 21.4                         & 0    \\ \hline
PUResNet      & 2360 (85.1\%) & 2621 ($\times$0.4)  & 1, 1, 4             & 8.1                              & 27                           & 0    \\ \hline
DeepPocket\textsubscript{SEG} & 2349 (84.7\%) & 21,718 ($\times$3.2) & 1, 6, 196           & 7.7                              & 4.6                          & 0.4  \\ \hline
P2Rank\textsubscript{CONS}    & 2759 (92.9\%) & 12,412($\times$1.8)  & 1, 3, 57            & 7.1                              & 13.9                         & 0.05 \\ \hline
P2Rank        & 2402 (86.6\%) & 10,180 ($\times$1.5) & 1, 3, 85            & 7.1                              & 13.8                         & 0.05 \\ \hline
fpocket       & 2759 (99.4\%) & \textbf{57,859 ($\times$8.4}) & 1, 17, \textbf{349}          & 6.3                              & 9.7                          & 0.15 \\ \hline
PocketFinder\textsuperscript{+} & 2775 (100\%)   & 8913 ($\times$1.3)  & 1, 3, 23            & 8.6                              & 18.7                         & 0.05 \\ \hline
Ligsite\textsuperscript{+}      & 2775 (100\%)   & 6903 ($\times$1.0)  & 1, 2, 12            & \textbf{9.1} & 16.7                         & 0.09 \\ \hline
Surfnet\textsuperscript{+}      & 2775 (100\%)   & 9043 ($\times$1.3)  & 1, 3, 40            & 8.4                              & 17.2                         & 0.07 \\ \hline
\caption[Ligand site characterisation]{\textbf{Ligand site characterisation.} LIGYSIS is not a ligand site predictor, but a reference dataset derived from experimentally determined protein-ligand complexes. These predictions result from the default prediction of the methods, indicated by \textbf{(d)} preceding method names. Coverage is the number of chains where methods predict at least one pocket. Percentage is relative to number of LIGYSIS chains. Total number of pockets and ratio of predicted pockets per reference site in parenthesis, e.g., for each LIGYSIS site, fpocket predicts 8.4 pockets on average; Minimum, median and maximum number of predicted pockets per chain; Median pocket radius of gyration $R_{g}$ (\AA{}); Minimum centroid distance (MCD) (\AA{}) measures how close predicted pockets are; Maximum residue overlap (MRO) measures residue overlap between pockets, e.g., the median overlap between VN-EGNN predicted pockets is 85\%. Bold font indicates the most extreme values within each column.}
\label{tab:pocket_features_stats}\\
\end{longtable}
\end{landscape}

\begin{landscape}
\begin{longtable}[c]{|M{29mm}|M{29mm}|M{31mm}|M{27mm}|M{30mm}|M{19mm}|M{18mm}|M{18mm}|}
\hline
\textbf{Method}         & \textbf{Recall\textsubscript{top-$N$}} (\%) & \textbf{Recall\textsubscript{top-$N$+2}} (\%) & \textbf{Recall\textsubscript{max}} (\%) & \textbf{Precision\textsubscript{1K}} (\%) & \textbf{\# TP\textsubscript{100 FP}} & \textbf{RRO} (\%) & \textbf{RVO} (\%) \\ \hline
\endfirsthead
%
\footnotesize{(\textbf{d})} VN-EGNN        & 27.5 (\#11)           & 40.9 (\#12)             & 49.3 (\#10)         & \textbf{\textcolor{CBBlue}{92.5 (\#1)}}                   & \textbf{\textcolor{CBBlue}{1301 (\#1)}}               & \textbf{\textcolor{CBOrange}{32.8 (\#12)}}             & \textbf{\textcolor{CBOrange}{27.6 (\#11)}}             \\ \hline
\footnotesize{(\textbf{d})} IF-SitePred    & \textbf{\textcolor{CBOrange}{19.8 (\#12) }}           & \textbf{\textcolor{CBOrange}{25.7 (\#13)}}             & 52.1 (\#6)         & 91.0 (\#2)             & 961 (\#3)         & 46.5 (\#11)     & 40.4 (\#9)     \\ \hline
\footnotesize{(\textbf{d})} GrASP          & 48.0 (\#2)              & 49.9 (\#5)             & 50.0 (\#8)           & \textbf{\textcolor{CBBlue}{92.5 (\#1)}}                   & 1017 (\#2)       & 54.5 (\#7)     & 59.8 (\#6)     \\ \hline
\footnotesize{(\textbf{d})} PUResNet       & 40.6 (\#6)            & 41.1 (\#11)             & \textbf{\textcolor{CBOrange}{41.1 (\#12)}}         & 81.6 (\#6)           & 534 (\#8)         & 61.0 (\#4)     & 63.9 (\#4)     \\ \hline
\footnotesize{(\textbf{d})} DeepPocket\textsubscript{SEG}  & 35.4 (\#10)            & 43.8 (\#10)             & 56.5 (\#5)         & 82.6 (\#4)           & 670 (\#5)         & 57.5 (\#5)     & 60.3 (\#5)     \\ \hline
\footnotesize{(\textbf{d})} DeepPocket\textsubscript{RESC} & 46.6 (\#4)            & 58.1 (\#2)                     & 89.3 (\#2)         & 81.7 (\#5)          & 637 (\#6)         & 53.1 (\#9)     & 38.2 (\#10)     \\ \hline
\footnotesize{(\textbf{d})} P2Rank\textsubscript{CONS}     & \textbf{\textcolor{CBBlue}{48.8 (\#1)}}           & 53.9 (\#3)             & 57.0 (\#4)           & 90.7 (\#3)           & 932 (\#4)         & 56.4 (\#6)     & 43.8 (\#8)     \\ \hline
\footnotesize{(\textbf{d})} P2Rank         & 46.7 (\#3)            & 51.9 (\#4)             & 57.0 (\#4)           & 79.2 (\#7)           & 586 (\#7)         & 54.4 (\#8)     & 58.2 (\#7)   \\ \hline
\footnotesize{(\textbf{d})} fpocket\textsubscript{PRANK}        & \textbf{\textcolor{CBBlue}{48.8 (\#1)}}           & \textbf{\textcolor{CBBlue}{60.4 (\#1)}}             & \textbf{\textcolor{CBBlue}{91.3 (\#1)}}         & 81.7 (\#5)           & 526 (\#9)          & 52.6 (\#10)     & 38.2 (\#10)     \\ \hline
\footnotesize{(\textbf{d})} fpocket        & 38.8 (\#8)           & 46.5 (\#8)             & \textbf{\textcolor{CBBlue}{91.3 (\#1)}}         & 47.3 (\#9)           & 94 (\#11)          & 52.6 (\#10)     & 38.2 (\#10)     \\ \hline
\footnotesize{(\textbf{d})} PocketFinder\textsuperscript{+}  & 39.2 (\#7)           & 47.8 (\#7)             & 50.5 (\#7)         & 42.0 (\#10)             & 64 (\#12)          & 72.3 (\#2)     & 75.9 (\#2)     \\ \hline
\footnotesize{(\textbf{d})} Ligsite\textsuperscript{+}       & 41.3 (\#5)           & 48.4 (\#6)             & 49.7 (\#9)         & 52.3 (\#8)           & 115 (\#10)         & \textbf{\textcolor{CBBlue}{77.6 (\#1)}}             & \textbf{\textcolor{CBBlue}{77.0 (\#1)}}             \\ \hline
Surfnet\textsuperscript{+}       & 37.7 (\#9)           & 45.8 (\#9)             & 48.9 (\#11)         & \textbf{\textcolor{CBOrange}{39.5 (\#11)}}           & \textbf{\textcolor{CBOrange}{61 (\#13)}}                  & 71.7 (\#3)     & 72.0 (\#3)     \\ \hline
\caption[Pocket level evaluation]{\textbf{Pocket level evaluation.} These metrics correspond to the default modes of the thirteen methods covered in this benchmark, indicated by (\textbf{d}) preceding methods' names. Recall for each method considering top-$N$, $N$+2 and \textit{all} predictions (max) without taking rank into consideration, i.e., maximum recall. Precision of the method for the top-1000 scored predictions. Number of TP reached for the first 100 FP (\# TP\textsubscript{100 FP}). Mean relative residue overlap (RRO) for those sites correctly predicted and relative volume overlap (RVO) only for correctly predicted sites that have a volume, i.e., are pockets or cavities, and not exposed sites, which do not have a volume. These last two metrics represent the overlap in residues and volume relative to the observed site. See CROSSREF to Methods section for definitions of RRO and RVO. Bold font indicates the best (blue) and worst (orange) performing methods for each metric.}
\label{tab:pocket_level_benchmark}\\
\end{longtable}
\end{landscape}

\subsection{Evaluation of predictive performance}

\subsubsection{Pocket level evaluation}

The ideal ligand binding site predictor would have a high precision, i.e., most of the predictions it makes are correct, whilst maintaining a high recall, i.e., recapitulating most of the observed sites. Moreover, the ideal predictor returns predictions that are non-redundant, i.e., it does not predict the same pocket multiple times. Additionally, pockets are ranked in a systematic manner according to a strong and meaningful pocket scoring scheme which captures well the nature of existing ligand binding sites and therefore ranks the predicted pockets from more likely (high score, top) to least likely (low score, bottom). A good predictor would also perform well at the residue level. This means it is able of capturing the likelihood for a residue binding a ligand. This can be done by means of a residue ligandability score, which additionally might highlight key residues, the more ligandable within a binding site. Ligand site prediction methods were benchmarked with these criteria in mind.

\autorefpanel{fig:pocket_level_benchmark_OG}{A} illustrates the recall curve for top-$N$+2 pockets for each method, where $N$ is the number of observed sites for a target protein. Reported recall is obtained using DCC = 12 \AA{}. Re-scored fpocket predictions by PRANK (fpocket\textsubscript{PRANK}) and DeepPocket (DeepPocket\textsubscript{RESC}) yield the highest recall with 60.4\% and 58.1\%, closely followed by, P2Rank\textsubscript{CONS} (53.9\%) and P2Rank (51.9\%). The rest of the methods present recall $<$ 50\% with PUResNet, VN-EGNN and IF-SitePred presenting the lowest recalls of 41.1\%, 40.9\% and 25.7\%, respectively (\autoref{tab:pocket_level_benchmark}). \autorefpanel{fig:pocket_level_benchmark_OG}{B} shows the recall curve considering different top-$N$+$X$ predictions. Most methods reach a plateau by top-$N$+5, as they do not predict that many pockets. However, methods that predict more pockets per protein, such as IF-SitePred or fpocket, fpocket\textsubscript{PRANK}, DeepPocket\textsubscript{SEG} and DeepPocket\textsubscript{RESC}, which take fpocket predictions as a base, increase their recall as more predictions are considered. fpocket, fpocket\textsubscript{PRANK} and DeepPocket\textsubscript{RESC} reach a maximum recall of $\approx$90\% when \textit{all} predictions are considered, regardless of rank. Other methods present maximum recall of $\approx$50-60\%. \autorefpanel{fig:pocket_level_benchmark_OG}{C} depicts the recall curve if residue overlap was used instead of DCC as a criterion. In this case, Ligsite\textsuperscript{+}, PocketFinder\textsuperscript{+}, and Surfnet\textsuperscript{+} come on top with recall $\approx$45\% at $I_{rel} \geq$ 0.5. This is explained by their prediction of massive cavities, that while often fully contain or overlap with the observed pocket, do not meet the DCC criterion, as their centroids are farther than 12 \AA{} from the observed site.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG7_POCKET_LEVEL_BENCHMARK_OG.png}
    \caption[Ligand binding site prediction benchmark at the pocket level]{\textbf{Ligand binding site prediction benchmark at the pocket level.} These curves correspond to the default predictions of the thirteen methods,
indicated by (\textbf{d}) preceding their names. \textbf{(A)} Recall, percentage of observed sites that are correctly predicted by a method within the top-$N$+2 predictions according to a DCC = 12 \AA{} threshold; \textbf{(B)} Recall using DCC = 12 \AA{} but considering increasing rank thresholds, i.e., top-$N$, $N$+1, $N$+2, etc. \textit{all} represents the maximum recall of a method, obtained by considering all predictions, regardless of their rank or score; \textbf{(C)} Recall curve for top-$N$+2 predictions using $I_{rel}$ as a criterion; \textbf{(D)} ROC100 curve (cumulative \#TP against cumulative FP until 100 FP are reached); \textbf{(E)} Precision curve for the top-1000 predictions of each method across the LIGYSIS dataset, Precision\textsubscript{1K}. Error bars represent 95\% CI of the recall (A-C) and precision (E), which is 100 $\times$ proportion. Numbers at the right of the panels indicate groups or blocks of methods that perform similarly for each metric. Stars (*) indicate outlier methods, or methods that perform very differently than the rest.}
    \label{fig:pocket_level_benchmark_OG}
\end{figure}

\autorefpanel{fig:pocket_level_benchmark_OG}{D} represents the cumulative number of TP against FP when predictions across the proteins in the reference dataset are sorted by score. This shows how effective the scoring scheme of each method is in ranking their predictions to reflect the nature of ligand binding sites. At 100 FP the \#TP fall into three different blocks and one outlier: Ligsite\textsuperscript{+}, fpocket, Surfnet\textsuperscript{+} and PocketFinder\textsuperscript{+} are at the bottom with \#TP $\ni$ (60, 120). Secondly, fpocket\textsubscript{PRANK}, DeepPocket\textsubscript{SEG}, DeepPocket\textsubscript{RESC}, P2Rank, and PUResNet follow with \#TP $\ni$ (530, 670). Re-scoring fpocket predictions with PRANK or DeepPocket results in up to +500 TP. GrASP, IF-SitePred and P2Rank\textsubscript{CONS}, present a high \#TP ranging 900-1000 at 100 FP. Finally, VN-EGNN sits at the top with 1301 TP. However, this number might not be representative, as the \#TP could be inflated due to the redundancy in the predictions of VN-EGNN. This is the same for IF-SitePred and DeepPocket\textsubscript{SEG}. Redundant correct predictions of the same pocket will count as multiple TPs, whereas they should only count as 1 TP. Newer methods, e.g., GrASP, P2Rank\textsubscript{CONS}, and VN-EGNN and IF-SitePred, despite redundancy in their prediction for the latter two, are better at ranking their predicted pockets, presenting up to 1000 more TP for 100 FP than earlier methods. This means their scoring schemes are significantly better at capturing the essence of a ligand binding site. Including evolutionary conservation in P2Rank (P2Rank\textsubscript{CONS}) results in an increase of +346 TP relative to default P2Rank, indicating that the fewer predicted pockets, and their scores are a more faithful representation of the observed LIGYSIS dataset.

\autorefpanel{fig:pocket_level_benchmark_OG}{E} provides insight into the precision of the methods by examining how this metric changes as more predictions are considered. In the same manner as for \autorefpanel{fig:pocket_level_benchmark_OG}{D}, predictions across proteins in the LIGYSIS dataset are sorted and cumulative precision is plotted for the top-1000 scoring predictions. Methods group into two clear blocks. Newer (machine learning-based) methods VN-EGNN, GrASP, IF-SitePred, P2Rank\textsubscript{CONS}, DeepPocket\textsubscript{SEG}, , fpocket\textsubscript{PRANK}, DeepPocket\textsubscript{RESC} and PUResNet present a Precision\textsubscript{1K} of 80-95\%. Earlier (geometry/energy-based) methods Ligsite\textsuperscript{+}, fpocket, Pocket-Finder\textsuperscript{+} and Surfnet\textsuperscript{+} present lower Precision\textsubscript{1K} of 40-50\%. fpocket\textsubscript{PRANK} and DeepPocket\textsubscript{RESC} take fpocket (geometry-based) predictions as a starting point and achieve much higher \#TP\textsubscript{100FP} (+500) as well as Precision\textsubscript{1K} (+30\%). This is further evidence that performance can be boosted with a solid scoring scheme and agrees with previous studies \cite{KRIVAK_2015_PRANK, KRIVAK_2015_P2RANK, KRIVAK_2018_P2RANK, COMAJUNCOSA_2024_POCKETS}.

\autoref{tab:pocket_level_benchmark} summarises these results and shows the mean relative residue overlap (RRO) and relative volume overlap (RVO), which measure how well predicted sites align with observed ones in shape. VN-EGNN and IF-SitePred present the smallest RRO and RVO, but it is important to note that these methods do not report pocket residues and so residues were taken within 6 \AA{} of their centroid, or pocket spheres. PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+}, and Surfnet\textsuperscript{+} present unusually high RRO and RVO. This is a consequence of the massive size of their predicted cavities, that rather than overlap with the observed site, fully contain and are much larger than it. This might not be convenient in the context of pocket finding for drug discovery where more clearly defined drug-like sites might be of interest. GrASP, PUResNet and DeepPocket\textsubscript{SEG} present high values of RRO $\approx$ 60\% and RVO $\approx $60\% whilst presenting a size distribution more like LIGYSIS (\autorefpanel{fig:pocket_features_1}{B}) and provide the best representation of the observed sites in terms of shape similarity.

\subsubsection{Residue level evaluation}

Ligand binding site prediction tools can also be evaluated at the residue level. F1 Score as well as Matthews correlation coefficient (MCC) were utilised to do so. For each protein chain, F1 and MCC were calculated, distributions graphed and means reported (\autoref{tab:residue_level_benchmark}). Binary labels are employed to calculate these scores, $1$ if the residue is found in a pocket and $0$ otherwise, and compared to the ground truth, i.e., whether a residue binds a ligand in the LIGYSIS set. For VN-EGNN, IF-SitePred, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+}, and Surfnet\textsuperscript{+}, which do not report pocket residues \autoref{tab:methods_details_1}, pocket residues were obtained by considering those residues within 6 \AA{} of the pocket centroid, cloud, or grid points, respectively. DeepPocket\textsubscript{RESC} was not considered for this analysis since the predictions are re-scored and re-ranked fpocket predictions.

\autorefpanel{fig:residue_level_benchmark}{A,B} illustrate the distributions of the F1 score and MCC for each method on the 2775 protein chains of the final LIGYSIS set. Both metrics agree that PUResNet (F1 = 0.41, MCC = 0.39), GrASP (F1 = 0.39, MCC = 0.33) and P2Rank\textsubscript{CONS} (F1 = 0.36, MCC = 0.30) are the top-3 performing methods in this task of binary classification into pocket ($1$) and non-pocket residues ($0$). fpocket presents the lowest F1 = 0.23 and MCC = 0.12 since it predicts many unobserved pockets (residues) that will count as FP here.

IF-SitePred does not report a residue ligandability score beyond a binary label ($0$, $1$). Nevertheless, in this chapter, a score was computed by utilising the scores returned by the 40 prediction models of IF-SitePred. These scores range 0-1 and can be averaged as probabilities (\autoref{eq:IFSP_score}). This will now be referenced as IF-SitePred ligandability score. For IF-SitePred, GrASP, P2Rank\textsubscript{CONS}, P2Rank, PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+}, and Surfnet\textsuperscript{+}, which report a residue level score (beyond a binary label), ROC and PR curves were plotted (\autorefpanel{fig:residue_level_benchmark}{C}) and mean area under the curve (AUC) and mean average precision (AP) reported. This was not possible for VN-EGNN, PUResNet, DeepPocket\textsubscript{SEG}, DeepPocket\textsubscript{RESC}, fpocket\textsubscript{PRANK} and fpocket as they do not report residue ligandability scores. \autoref{fig:ROC_variation} illustrates the variation in ROC/AUC for each method across the 2775 chains in the LIGYSIS set. P2Rank\textsubscript{CONS} and IF-SitePred, with the ligandability score calculated in this work (\autoref{eq:IFSP_score}), present the highest mean AUC = 76\%, closely followed by P2Rank (AUC = 74\%). Surfnet\textsuperscript{+} presents the lowest AUC = 68\%. \autorefpanel{fig:residue_level_benchmark}{D} shows the mean PR curves, which agree with ROC AUC and highlight P2Rank\textsubscript{CONS} as the method with the highest average precision = 46\%, followed by IF-SitePred (with \autoref{eq:IFSP_score} scoring) with AP = 45\% and PocketFinder\textsuperscript{+} the lowest with (AP = 34\%). \autoref{fig:PR_variation} displays the variability across LIGYSIS proteins for PR curve and AP. \autorefpanel{fig:residue_level_benchmark}{E} shows IF-SitePred presenting a different residue ligandability score distribution to GrASP, P2Rank\textsubscript{CONS}, and P2Rank. The IF-SitePred ligandability score, resulting from averaging the scores from the 40 IF-SitePred models, is the most ``generous'' with $\approx$20\% of the residues presenting a score $>$ 0.5, in contrast with GrASP which residue scoring is very strict $P$($LS \geq$ 0.5) = 0.75\% and P2Ranks ($\approx$3\%). This difference, combined with the mean ROC and PR curves, further supports the use of the IF-SitePred ligandability score proposed in this chapter to define the predicted binding sites for this method. It also suggests that GrASP might benefit from a less strict residue level scoring scheme. PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+} were not included in this analysis as their scores do not range 0-1 and very high scores ($>$25) can be obtained.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/FIG8_RESIDUE_LEVEL_BENCHMARK.png}
    \caption[Ligand binding site prediction benchmark at the residue level]{\textbf{Ligand binding site prediction benchmark at the residue level.} DeepPocket\textsubscript{RESC} predictions are not included in F1 and MCC analyses as these are re-scored and re-ranked fpocket predictions and the results would be the same as for fpocket. \textbf{(A)} F1 score distributions; \textbf{(B)} MCC distributions. In both panels, each data point corresponds to the score obtained from all residues in a protein chain; \textbf{(C)} Mean ROC curve for methods that report a residue score. Dashed line represents the baseline, 1 FP for each TP, i.e., diagonal and AUC = 50\%; \textbf{(D)} Mean PR curve. Dashed line represents the baseline, i.e., percentage of observed binding residues (true positives) = 10\%; \textbf{(E)} Distribution of residue ligandability scores for IF-SitePred, GrASP, P2Rank\textsubscript{CONS} and P2Rank. PocketFinder\textsuperscript{+}, Ligsite\textsuperscript{+} and Surfnet\textsuperscript{+} are not included as their scores do not range 0-1, and a small number of scores can reach values $>$ 25. These predictions are from the original methods run with default parameters (\textbf{d}).} 
    \label{fig:residue_level_benchmark}
\end{figure}

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG_X_ROC_variation.png}
    \caption[Variation in ROC curve and AUC across LIGYSIS proteins]{\textbf{Variation in ROC curve and AUC across LIGYSIS proteins.} For each of the methods that report or for which residue ligandability scores were calculated, a ROC curve was calculated for each of the 2775 protein chains in the LIGYSIS set and AUC calculated. Plotted curves represent the mean ROC curve for each method. These are obtained by averaging the TPR for each FPR interval across proteins. Shaded area represents one standard deviation (1 SD) from the mean ROC curve. Reported AUC is the mean AUC calculated by averaging the AUC for the 2775 ROC curves obtained. Baseline AUC is random chance (AUC = 50\%). \textbf{(A)} IF-SitePred; \textbf{(B)} GrASP; \textbf{(C)} P2Rank\textsubscript{CONS}; \textbf{(D)} P2Rank; \textbf{(E)} PocketFinder\textsuperscript{+}; \textbf{(F)} Ligsite\textsuperscript{+}; \textbf{(G)} Surfnet\textsuperscript{+}. These results originate from default methods, indicated by (\textbf{d}) preceding method names.}
    \label{fig:ROC_variation}
\end{figure}

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG_X_PR_variation.png}
    \caption[Variation in PR curve and AP across LIGYSIS proteins]{\textbf{Variation in PR curve and AP across LIGYSIS proteins.} For each of the methods that report or for which residue ligandability scores were calculated, a precision-recall (PR) curve was calculated for each of the 2775 protein chains in the LIGYSIS set and average precision (AP) calculated. Plotted curves represent the mean PR curve for each method. These are obtained by averaging the precision for each recall interval across proteins. Shaded area represents one standard deviation (1 SD) from the mean PR curve. Reported AP is the mean AP calculated by averaging the AP for the 2775 PR curves obtained. Baseline AP is the percentage of observed ligand-binding residues (AP = 10\%). \textbf{(A)} IF-SitePred; \textbf{(B)} GrASP; \textbf{(C)} P2Rank\textsubscript{CONS}; \textbf{(D)} P2Rank; \textbf{(E)} PocketFinder\textsuperscript{+}; \textbf{(F)} Ligsite\textsuperscript{+}; \textbf{(G)} Surfnet\textsuperscript{+}. These results originate from default methods, indicated by (\textbf{d}) preceding method names.}
    \label{fig:PR_variation}
\end{figure}

\FloatBarrier

\begin{longtable}[c]{|c|c|c|c|c|}
\hline
\textbf{Method}         & \textbf{F1}   & \textbf{MCC}  & \textbf{AUC} (\%)  & \textbf{AP} (\%)   \\ \hline
\endfirsthead
%
\footnotesize{(\textbf{d})} VN-EGNN        & 0.29 (\#8) & 0.26 (\#4) & --    & --    \\ \hline
\footnotesize{(\textbf{d})} IF-SitePred    & 0.29 (\#9) & 0.24 (\#6) & 76 (\#2)  & 45 (\#2) \\ \hline
\footnotesize{(\textbf{d})} GrASP          & 0.39 (\#2) & 0.34 (\#2) & 70 (\#4) & 42 (\#3) \\ \hline
\footnotesize{(\textbf{d})} PUResNet       & \textbf{\textcolor{CBBlue}{0.41 (\#1)}} & \textbf{\textcolor{CBBlue}{0.39 (\#1)}} & --    & --    \\ \hline
\footnotesize{(\textbf{d})} DeepPocket\textsubscript{SEG}  & 0.27 (\#10) & 0.21 (\#9) & --    & --    \\ \hline
\footnotesize{(\textbf{d})} P2Rank\textsubscript{CONS}     & 0.36 (\#3) & 0.30 (\#3)  & \textbf{\textcolor{CBBlue}{76 (\#1)}} & \textbf{\textcolor{CBBlue}{46 (\#1)}} \\ \hline
\footnotesize{(\textbf{d})} P2Rank         & 0.31 (\#4) & 0.26 (\#5) & 74 (\#3) & 42 (\#3) \\ \hline
\footnotesize{(\textbf{d})} fpocket        & \textbf{\textcolor{CBOrange}{0.23 (\#11)}} & \textbf{\textcolor{CBOrange}{0.12 (\#11)}} & --    & --    \\ \hline
\footnotesize{(\textbf{d})} PocketFinder\textsuperscript{+}  & 0.31 (\#5) & 0.22 (\#7) & 68 (\#6) & \textbf{\textcolor{CBOrange}{34 (\#6)}} \\ \hline
\footnotesize{(\textbf{d})} Ligsite\textsuperscript{+}       & 0.31 (\#6) & 0.21 (\#8) & 70 (\#5) & 38 (\#4) \\ \hline
\footnotesize{(\textbf{d})} Surfnet\textsuperscript{+}       & 0.29 (\#7) & 0.20 (\#10)  & \textbf{\textcolor{CBOrange}{68 (\#7)}} & 35 (\#5) \\ \hline
\caption[Residue level evaluation]{\textbf{Residue level evaluation.} These results come from default predictions, indicated by (\textbf{d}). DeepPocket\textsubscript{RESC} was not considered in this analysis as their predictions are re-scored and re-ranked fpocket's. Ligand binding site prediction benchmark at the residue level was calcualted from 1775 protein chains in the LIGYSIS set. Mean F1 score,mean Matthews correlation coefficient (MCC), mean ROC area under the curve (AUC) and mean precision recall (PR) curve average precision (AP). Numbers following a hash (\#) indicate how methods rank for each metric. Bold font indicates the best (blue) and worst (orange) performing methods. Pocket binary labels ($0$, $1$) were employed for the calculation of F1 and MCC and obtained form predicted pockets. Residue ligandability scores were employed to calculate ROC/AUC and PR/AP. Reported AUC and AP are means resulting from the average across the 2775 LIGYSIS chains. This was not possible for VN-EGNN, PUResNet, DeepPocket\textsubscript{SEG} and fpocket as these methods do not provide such scores, indicated by a dash (--).}
\label{tab:residue_level_benchmark}\\
\end{longtable}

\section{Discussion}

This chapter describes the most complete comparative analysis of ligand binding site prediction methods to date, spanning three decades of methods development. Firstly, predictions from the thirteen methods as well as observed sites from the new reference dataset introduced here, LIGYSIS, were compared in terms of the number of proteins methods predict on, the number of predicted sites per protein, their size, distance and overlap between the sites. This analysis provides insight into how the different methods work and hints at potential limitations or room for improvement, e.g., the prediction of a fixed number of sites per protein, or considerable proximity and overlap between the predictions. Secondly, predictions from thirteen canonical ligand binding site prediction methods are objectively evaluated using the LIGYSIS set. This evaluation considers prediction at the residue level by F1 score, MSCC, ROC/AUC and PR/AP, as well as the pocket level by recall for top-$N$, $N$+2 and \textit{all} predictions, precision\textsubscript{1K}, \# TP\textsubscript{100 FP}, RRO and RVO. This is the first independent ligand site prediction benchmark since Schmidtke \textit{et al.} \cite{SCHMIDTKE_2010_BENCHMARK} in 2010 and Chen \textit{et al.} \cite{CHEN_2011_ASSESSMENT} shortly after in 2011 and the largest to date both in terms of reference dataset size (2775), methods compared (10) and metrics employed ($>$10).

Recall (\% of observed sites that are correctly predicted) is more informative than precision (\% of predictions that are correct), particularly, recall considering top-$N$+2 ranked predictions. In most cases, not all the existing binding pockets are observed with a ligand bound. In other words, the reference data are incomplete, with 33-50\% of existing sites yet to be observed with ligands bound in a structure, as conjectured by Krivák and Hoksza \cite{KRIVAK_2018_P2RANK}. Considering only the top-$N$ predicted pockets assumes that there are exactly $N$ real pockets for a given protein, which might not be the case. A method could predict a \textit{real} pocket that is yet to be observed and rank it before other predicted and observed pockets. By considering the top-$N$+2 pockets, the noise in the reference data is controlled for to some extent and a more accurate representation of the method performance is obtained. In a context of discovery, where the true ligand binding sites of the target are unknown, it is more useful to have multiple predictions that might or might not correspond to real sites (lower precision), rather than a single or few predictions that are very precise but are missing other likely sites (lower recall). Most methods do well in predicting the most obvious (orthosteric) site. This site, however, might not be available for therapeutic targeting and it is convenient to predict other sites that could modulate function acting as allosteric sites. Precision, though a metric that provides valuable insight, and covered in this work, must always be contextualised with recall. This chapter shows that the most precise methods do not correspond to higher recalling methods. A method predicting the most obvious site, that could be identified by eye, might be 90\% precise, but present a lower recall, e.g., 30\%. This said, methods predicting fewer pockets with higher precision might prove more advantageous when users aim to study a particular region of interest in a protein, a few high-priority sites are needed for experimental validation or false predictions are costly in downstream analysis. 

Some methods define ``success rate'' as the precision of the top-1 or top-3 scoring predictions, which is not a very representative performance assessment metric. For this reason, \textit{we} encourage method developers not only to share the code of their approach, but also of the benchmarking analysis. Furthermore, the definition of success rate must be standardised as recall, as some methods use recall, whereas others sue precision, both under the name of \textit{success rate}. This can be confusing when comparing the results from different analyses. Moreover, due to the inherent noise in the reference data, i.e., not all existing pockets are known, recall considering top-$N$+2 is more informative than taking top-1, top-3 or top-$N$ predictions. In any case, success rate must be clearly defined, so readers can fully understand the implications of the metric employed in a benchmark.

It is clear from the results described in this chapter that a DCC threshold of 4 \AA{Å} is too conservative, and a more flexible DCC threshold of 10-12 \AA{} should be used for comparable performance with DCA = 4 \AA{}. According to this work and the LIGYSIS reference, predictions with DCC 4-12 \AA{} overlap or are adjacent to observed sites and should be considered as correct predictions. The reason for this is the inherent noise in the ground truth, i.e., a ligand binding to a cavity might not be representative of all ligands that could bind to it. For most proteins, not all existing ligand sites are characterised and as different ligands can bind to the same region, it is unrealistic to use such a small DCC threshold. Our results show several examples of predictions of an observed cavity where DCC $>$ 4 \AA{}.

The usefulness of residue-level metrics as F1 score or MCC is limited, as methods that precisely and correctly predict the clearest sites, such as PUResNet (high precision, low recall) perform better on these metrics, while methods that predict more pockets (lower precision, higher recall) such as fpocket and re-scored versions, will obtain worse results. Pocket-level metrics, such as top-$N$+2 recall, are more representative of the ability to predict ligand binding sites.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG_FULL_VS_NI_SPLIT1.png}
    \caption[Change in top-\textit{N}+2 recall for LIGYSIS \textit{vs} LIGYSIS\textsubscript{NI} (I)]{\textbf{Change in top-\textit{N}+2 recall for LIGYSIS \textit{vs} LIGYSIS\textsubscript{NI} (I).} Recall is calculated considering top-$N$+2 pockets at DCC = 12 \AA{} and default methods (\textbf{d}) on a set of LIGYSIS binding sites containing at least one non-ion ligand, N = 4141/6882 (60\%). Solid lines indicate recall curve on LIGYSIS and dashed lines for LIGYSIS\textsubscript{NI}. The relative change in recall and rank are indicated by $\Delta_{Recall}$ and $\Delta_{Rank}$. These changes are relative to performance on LIGYSIS (including ions). All machine learning-based methods present an increase in recall when removing ion binding sites. This is expected ad none of the methods are trained on ion sites. However, ion sites were kept on the main benchmark to challenge and test the limits of the methods. \textbf{(A)} VN-EGNN; \textbf{(B)} IF-SitePred; \textbf{(C)} GrASP; \textbf{(D)} PUResNet; \textbf{(E)} DeepPocket\textsubscript{SEG}; \textbf{(F)} DeepPocket\textsubscript{RESC}; \textbf{(G)} P2Rank\textsubscript{CONS}; \textbf{(H)} P2Rank; \textbf{(I)} fpocket\textsubscript{PRANK}.}
    \label{fig:LIGYSIS_VS_LIGYSISNI_1}
\end{figure}

While datasets like PDBbind, binding MOAD or the brand new PLINDER \cite{DURAIRAJ_2024_PLINDER} (will) prove extremely useful to train, validate and test deep learning models tackling problems such as rigid body docking \cite{STARK_2022_EQUIBIND}, flexible pocket docking \cite{QIAO_2024_DGN}, or pocket-conditioned ligand generation \cite{SCHNEUING_2023_DIFFUSION}, they might not be ideal as a test set for ligand binding site prediction. LIGYSIS analyses all unique, biologically relevant protein-ligand interfaces, including ions, across the biological assembly from multiple experimentally determined structures of a given protein. It then clusters these ligands based on their interactions with the protein, resulting in the observed binding sites. Beyond considering biological assemblies and unique protein-ligand interfaces, the greatest innovation in LIGYSIS is leveraging the extensive structural data on the PDBe-KB to aggregate ligand-binding interactions across different structures of the same protein, thus better capturing the ligand-binding capabilities than just taking a single structure of a protein-ligand complex. In doing so, LIGYSIS represents the most complete and non-redundant protein-ligand complex dataset to date for the prediction of protein-ligand binding sites.

The benchmark is performed on LIGYSIS, which includes ion binding sites. When these are removed, all methods, except for fpocket, experience an increase in (top-$N$+2) recall of 5-10\% and the overall ranking of methods does not change (\autoref{fig:LIGYSIS_VS_LIGYSISNI_1} and \autoref{fig:LIGYSIS_VS_LIGYSISNI_2}. Due to its integrative approach, features, diversity and size (covering $>$30\$ of PDB and $>$20\% of BioLiP), LIGYSIS is the most inclusive and representative dataset of protein-ligand interactions.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\textwidth]{figures/ch_LBS_COMP/PNG/SUPP_FIG_FULL_VS_NI_SPLIT2.png}
   \caption[Change in top-\textit{N}+2 recall for LIGYSIS \textit{vs} LIGYSIS\textsubscript{NI} (II)]{\textbf{Change in top-\textit{N}+2 recall for LIGYSIS \textit{vs} LIGYSIS\textsubscript{NI} (II).} Recall is calculated considering top-$N$+2 pockets at DCC = 12 \AA{} and default methods (\textbf{d}) on a set of LIGYSIS binding sites containing at least one non-ion ligand, N = 4141/6882 (60\%). Solid lines indicate recall curve on LIGYSIS and dashed lines for LIGYSIS\textsubscript{NI}. The relative change in recall and rank are indicated by $\Delta_{Recall}$ and $\Delta_{Rank}$. These changes are relative to performance on LIGYSIS (including ions). Geometry and energy-based methods also present an increase in recall when removing ion binding sites. This is expected ad none of the methods are trained on ion sites. However, ion sites were kept on the main benchmark to challenge and test the limits of the methods. fpocket is an exception to this, suggesting this method \textit{does} not struggle with ion binding sites as much as other methods do.}
    \label{fig:LIGYSIS_VS_LIGYSISNI_2}
\end{figure}

Aggregating protein-ligand interactions across structures of the same protein is likely to be beneficial not only for testing, but also when training these methods. Most current methods train on datasets where a protein is represented by a single structure interacting with a single ligand. For example, in 100\% of sc-PDB and 50\% of entries for binding MOAD training sets. Methods consider as ligand binding, and therefore TP, those residues within a certain distance of the ligand and TN all other residues. In doing so, residues of the same protein that bind ligands on other structures, but not the one present on these sets, will be incorrectly labelled as ``non-ligand-binding'' (FN). This mislabelling of residues could lead to a lower prediction performance. This issue is to a certain extent approached by P2Rank and GrASP, which enriched their training datasets by including ligands from other chains, or homologous structures. This noise in the training dataset might be more prevalent for DeepPocket, PUResNet and VN-EGNN, which seem to rely fully on 1:1 interactions. The usage of LIGYSIS, or any other data set that aggregates ligand interactions across structures, might alleviate this issue and hints at potential room for improvement in the field of ligand binding site prediction.

\section{Conclusions}

The conclusions resulting from the analysis described in this chapter are as follows:

\begin{itemize}

\item Ligand binding site prediction methods differ significantly in the number of predicted sites, their size, proximity and overlap, which offers insight into how the methods work.

\item Recall is a more informative measure of the performance of a ligand site prediction tool, rather than precision and so it must be reported. Precision, though a useful metric, should always be contextualised with recall.

\item LIGYSIS aggregates non-redundant biologically relevant protein-ligand interactions across multiple structures for a protein and sets a new test set standard for the benchmark of ligand binding site prediction tools. 

\item All authors of ligand site prediction tools should use top-$N$+2 recall as ``success rate'' for consistency. Benchmarking code should also be shared by the authors for the sake of reproducibility.

\item Pocket-level metrics (recall, precision) are a more adequate representation of the capabilities of ligand site prediction methods than residue-level metrics (F1, MCC).

\item A DCC threshold of 4 \AA{} is too conservative, and to obtain comparable results between DCA and DCC recall, a threshold of DCC of 10-12 \AA{} should be employed.

\item Re-scoring of fpocket predictions, like fpocket\textsubscript{PRANK} or DeepPocket\textsubscript{RESC} present the highest (top-$N$+2) recall (60\%) among the methods reviewed in this analysis.

\item Methods that systematically predict a low number of pockets, e.g., VN-EGNN, GrASP or PUResNet, are very precise ($>$90\%), however their recall is low, and might not be as useful in a discovery context.

\item The IF-SitePred ligandability scored introduced in this work correctly recapitulates observed ligand binding sites and suggests IF-SitePred could benefit greatly from using it in their prediction.

\item The use of duplicated protein-ligand interfaces in asymmetric units results in an overestimate of both precision and recall when benchmarking ligand site predictors. Only unique protein-ligand interfaces in biological units should be considered for a more accurate benchmark of the performance of these methods.

\item The work presented in this chapter objectively evaluates the performance of thirteen canonical ligand binding site prediction methods and represents the largest benchmark of ligand site prediction tools to date.

\end{itemize}
